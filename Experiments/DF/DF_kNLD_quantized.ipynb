{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "directory = \"/content/dataset\"\n",
        "if any(os.listdir(directory)):\n",
        "  print('dataset exists')\n",
        "else:\n",
        "  !unzip /content/DF_dataset -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SFdnbZgRVmv",
        "outputId": "09a2f4e0-9ff5-4c96-920c-7e993653effb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/DF_dataset.zip\n",
            "  inflating: /content/dataset/X_test_NoDef.pkl  \n",
            "  inflating: /content/dataset/X_train_NoDef.pkl  \n",
            "  inflating: /content/dataset/X_valid_NoDef.pkl  \n",
            "  inflating: /content/dataset/y_test_NoDef.pkl  \n",
            "  inflating: /content/dataset/y_train_NoDef.pkl  \n",
            "  inflating: /content/dataset/y_valid_NoDef.pkl  \n",
            "  inflating: /content/dataset/ziping.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 15D1vov_iXPWMpGO6-xnb-M6aDXWPxtHD\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYBY7tdaaTEC",
        "outputId": "43295d93-284f-4886-fa71-595212fad814"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15D1vov_iXPWMpGO6-xnb-M6aDXWPxtHD\n",
            "To: /content/X_test_Unmon_NoDef.pkl\n",
            "100% 801M/801M [00:09<00:00, 88.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/X_test_Unmon_NoDef.pkl /content/dataset/openset.pkl"
      ],
      "metadata": {
        "id": "H299FnQf1-9N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PM1cPJ_soczA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from utility import LoadDataIot\n",
        "from Model_NoDef import DFNet_Robust\n",
        "import random\n",
        "import tensorflow\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "from sklearn.metrics import accuracy_score\n",
        "np_config.enable_numpy_behavior()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representative_data_gen_Open():\n",
        "  for input_value in tf.data.Dataset.from_tensor_slices(X__open).batch(1).take(1000):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size\n",
        "\n",
        "def convert_bytes(size, unit=None):\n",
        "    if unit == \"KB\":\n",
        "        return str(round(size / 1024, 3))\n",
        "    elif unit == \"MB\":\n",
        "        return str(round(size / (1024 * 1024), 3))\n",
        "    else:\n",
        "        return str(size)\n",
        "\n",
        "\n",
        "def Micro_F1(matrix):\n",
        "    epsilon = 1e-8\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "\n",
        "    for k in range(NB_CLASSES):\n",
        "        TP += matrix[k][k]\n",
        "        FP += (np.sum(Matrix, axis=0)[k] - matrix[k][k])\n",
        "        TN += (np.sum(Matrix, axis=1)[k] - matrix[k][k])\n",
        "\n",
        "    Micro_Prec = TP / (TP + FP)\n",
        "    Micro_Rec = TP / (TP + TN)\n",
        "    print(\"Micro Precision: \", Micro_Prec)\n",
        "    print(\"Micro Recall: \", Micro_Rec)\n",
        "    Micro_F1 = 2 * Micro_Prec * Micro_Rec / (Micro_Rec + Micro_Prec + epsilon)\n",
        "\n",
        "    return Micro_F1\n",
        "\n",
        "\n",
        "def New_F1_Score(Matrix):\n",
        "    epsilon = 1e-8\n",
        "    Column_sum = np.sum(Matrix, axis=0)\n",
        "    Raw_sum = np.sum(Matrix, axis=1)\n",
        "\n",
        "    Precision_Differences = []\n",
        "    Recall_Differences = []\n",
        "    for i in range(NB_CLASSES):\n",
        "        Precision_Differences.append(np.abs(2 * Matrix[i][i] - Column_sum[i]))\n",
        "        Recall_Differences.append(np.abs(2 * Matrix[i][i] - Raw_sum[i]))\n",
        "\n",
        "    Precision_Differences = np.array(Precision_Differences)\n",
        "    Precision_Differences_Per = Precision_Differences / (np.sum(Precision_Differences)+epsilon)\n",
        "    Recall_Differences = np.array(Recall_Differences)\n",
        "    Recall_Differences_Per = Recall_Differences / (np.sum(Recall_Differences)+epsilon)\n",
        "\n",
        "    # print('Precision_Differences_Per',Precision_Differences_Per)\n",
        "    # print('Recall_Differences_Per',Recall_Differences_Per)\n",
        "\n",
        "    Precisions = np.zeros(NB_CLASSES)\n",
        "    Recalls = np.zeros(NB_CLASSES)\n",
        "\n",
        "    for k in range(len(Precisions)):\n",
        "        Precisions[k] = (Matrix[k][k] / np.sum(Matrix, axis=0)[k])\n",
        "    Precision = np.sum(np.array(Precisions) * Precision_Differences_Per)\n",
        "\n",
        "    for k in range(len(Recalls)):\n",
        "        Recalls[k] = Matrix[k][k] / (np.sum(Matrix, axis=1)[k]+ epsilon)  # *Recall_Differences_Per[k]\n",
        "    Recall = np.sum(np.array(Recalls) * Recall_Differences_Per)\n",
        "\n",
        "    print('Precision: ', Precision)\n",
        "    print('Recall: ', Recall)\n",
        "\n",
        "    F1_Score = 2 * Precision * Recall / (Precision + Recall + epsilon)\n",
        "    return F1_Score\n",
        "\n",
        "\n",
        "def Macro_F1(Matrix):\n",
        "    Precisions = np.zeros(NB_CLASSES)\n",
        "    Recalls = np.zeros(NB_CLASSES)\n",
        "\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    for k in range(len(Precisions)):\n",
        "        Precisions[k] = Matrix[k][k] / (np.sum(Matrix, axis=0)[k]+epsilon)\n",
        "    # print(Precisions)\n",
        "\n",
        "    Precision = np.average(Precisions)\n",
        "    print(\"Precision:\", Precision)\n",
        "\n",
        "    for k in range(len(Recalls)):\n",
        "        Recalls[k] = Matrix[k][k] / (np.sum(Matrix, axis=1)[k]+epsilon)\n",
        "\n",
        "    Recall = np.average(Recalls)\n",
        "    print(\"Recall:\", Recall)\n",
        "\n",
        "    F1_Score = 2 * Precision * Recall / (Precision + Recall + epsilon)\n",
        "    return F1_Score"
      ],
      "metadata": {
        "id": "1xfCexiTEtKt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c47F0U2wuYf",
        "outputId": "adfd7189-9e59-48d1-c902-205037ed29b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NB_EPOCH = 30   # Number of training epoch\n",
        "print (\"Number of Epoch: \", NB_EPOCH)\n",
        "BATCH_SIZE = 128 # Batch size\n",
        "VERBOSE = 2 # Output display mode\n",
        "LENGTH = 1500 # Packet sequence length\n",
        "OPTIMIZER = Adamax(learning_rate=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08) # Optimizer\n",
        "\n",
        "NB_CLASSES = 95 # number of outputs = number of classes\n",
        "INPUT_SHAPE = (LENGTH,1)\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "print (\"Loading and preparing data for training, and evaluating the model\")\n",
        "X_train, y_train, X_valid, y_valid, X_test, y_test = LoadDataIot()\n",
        "\n",
        "# Convert data as float32 type\n",
        "X_train = X_train.astype('float32')\n",
        "X_valid = X_valid.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "y_valid = y_valid.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "\n",
        "# we need a [Length x 1] x n shape as input to the DF CNN (Tensorflow)\n",
        "X_train = X_train[:, :,np.newaxis]\n",
        "X_valid = X_valid[:, :,np.newaxis]\n",
        "X_test = X_test[:, :,np.newaxis]\n",
        "\n",
        "# Convert class vectors to categorical classes matrices\n",
        "y_train = to_categorical(y_train, NB_CLASSES)\n",
        "y_valid = to_categorical(y_valid, NB_CLASSES)\n",
        "y_test = to_categorical(y_test, NB_CLASSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm1lT_mRXJwD",
        "outputId": "78d44b44-62b3-4d79-e6bb-7d56fa1f6521"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch:  10\n",
            "Loading and preparing data for training, and evaluating the model\n",
            "Data dimensions:\n",
            "X: Training data's shape :  (76000, 1500)\n",
            "y: Training data's shape :  (76000,)\n",
            "X: Validation data's shape :  (9500, 1500)\n",
            "y: Validation data's shape :  (9500,)\n",
            "X: Testing data's shape :  (9500, 1500)\n",
            "y: Testing data's shape :  (9500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DFNet_Robust.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "print (\"Model compiled\")\n",
        "\n",
        "filepath = '/content/trained_models/DF.hdf5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Start training\n",
        "history = model.fit(X_train, y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "\t\tverbose=VERBOSE, validation_data=(X_valid, y_valid), callbacks=callbacks_list)\n",
        "\n",
        "#Start evaluating model with testing data\n",
        "\n",
        "model_penultimate = Model(model.input, model.layers[-2].output)\n",
        "model_penultimate.save('/content/trained_models/DF_without_softmax.hdf5')\n",
        "model_penultimate.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "score_test = model_penultimate.evaluate(X_test, y_test, verbose=VERBOSE)\n",
        "print(\"Testing closed accuracy_without_norm:\", score_test[1])\n",
        "\n",
        "\n",
        "del model\n"
      ],
      "metadata": {
        "id": "pHtdjBU9qAnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aacc5eaa-f345-4df5-96ac-a2a056b4212a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model compiled\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.71253, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 48s - loss: 2.5719 - accuracy: 0.3527 - val_loss: 1.0291 - val_accuracy: 0.7125 - 48s/epoch - 81ms/step\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_accuracy improved from 0.71253 to 0.88926, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 27s - loss: 1.0338 - accuracy: 0.7271 - val_loss: 0.4186 - val_accuracy: 0.8893 - 27s/epoch - 45ms/step\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.88926 to 0.91432, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 28s - loss: 0.6299 - accuracy: 0.8386 - val_loss: 0.3398 - val_accuracy: 0.9143 - 28s/epoch - 47ms/step\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.91432 to 0.93874, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 27s - loss: 0.4685 - accuracy: 0.8811 - val_loss: 0.2314 - val_accuracy: 0.9387 - 27s/epoch - 46ms/step\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.93874 to 0.93937, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 28s - loss: 0.3670 - accuracy: 0.9078 - val_loss: 0.2301 - val_accuracy: 0.9394 - 28s/epoch - 47ms/step\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.93937 to 0.95558, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 28s - loss: 0.3038 - accuracy: 0.9234 - val_loss: 0.1693 - val_accuracy: 0.9556 - 28s/epoch - 47ms/step\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.95558 to 0.96232, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 28s - loss: 0.2549 - accuracy: 0.9347 - val_loss: 0.1536 - val_accuracy: 0.9623 - 28s/epoch - 48ms/step\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.96232 to 0.96442, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 28s - loss: 0.2265 - accuracy: 0.9422 - val_loss: 0.1429 - val_accuracy: 0.9644 - 28s/epoch - 46ms/step\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.96442 to 0.96632, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 28s - loss: 0.1965 - accuracy: 0.9502 - val_loss: 0.1351 - val_accuracy: 0.9663 - 28s/epoch - 47ms/step\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.96632 to 0.96768, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 28s - loss: 0.1762 - accuracy: 0.9550 - val_loss: 0.1275 - val_accuracy: 0.9677 - 28s/epoch - 47ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "297/297 - 2s - loss: 16.0168 - accuracy: 0.9667 - 2s/epoch - 8ms/step\n",
            "Testing closed accuracy_without_norm: 0.9667368531227112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import _pickle as cPickle\n",
        "dataset_dir = \"/content/dataset/\"\n",
        "with open( dataset_dir+\"openset.pkl\",\"rb\") as f:\n",
        "        X_open = cPickle.load(f,encoding='latin1')\n",
        "X_open = np.array(X_open)\n",
        "X_open=X_open[:,:1500]\n",
        "print(X_open.shape)\n",
        "X_open = X_open.astype('float32')\n",
        "X__open = X_open[:,:,np.newaxis]\n",
        "y_open = np.array([NB_CLASSES]*len(X_open))\n",
        "y_open = y_open.astype('int8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUs0iOSobKOz",
        "outputId": "56263310-de1e-4be2-ba25-2496d688a50d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 1500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representative_data_gen():\n",
        "  for input_value in tensorflow.data.Dataset.from_tensor_slices(X_train_Rep).batch(1).take(1000):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "Block=1000\n",
        "X_train_Rep,y_train_Rep=shuffle(X_train, y_train)\n",
        "y_train=np.argmax(y_train, axis=1)\n",
        "y_valid=np.argmax(y_valid, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "X_test=np.squeeze(X_test, axis=-1)\n",
        "\n",
        "TF_LITE_MODEL_FILE_NAME = \"tf_lite_model_fullint.tflite\"\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_penultimate)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "#converter.target_spec.supported_types = [tf.float16]       # COnvert to 16 bit\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8  # or tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_name = \"/content/trained_models/\"+TF_LITE_MODEL_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)\n",
        "\n",
        "# print(\"Original Model Size:\",convert_bytes(get_file_size('/content/trained_models/IoT_without_softmax.hdf5'), \"KB\"),\"KB\")\n",
        "# print(\"Quantized model size:\",convert_bytes(get_file_size(tflite_model_name), \"KB\"),\"KB\")\n",
        "# print()\n",
        "\n",
        "#X_test=np.squeeze(X_test, axis=-1)\n",
        "interpreter = tf.lite.Interpreter(model_path = tflite_model_name)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], (Block, LENGTH, 1))       #change the input shape according to the test dataset dimenssions\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (Block, NB_CLASSES))\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_scale,input_zero_point  = input_details[0][\"quantization\"]\n",
        "\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  X_test[i] = X_test[i] / input_scale + input_zero_point\n",
        "\n",
        "X_test=X_test[:,:,np.newaxis]\n",
        "X_test = X_test.astype('int8')\n",
        "tflite_model_predictions_test=[]\n",
        "\n",
        "for i in range(5):\n",
        "  interpreter.set_tensor(input_details[0]['index'], X_test[i*Block:(i+1)*Block])\n",
        "  interpreter.invoke()\n",
        "  Mod_Prediction=interpreter.get_tensor(output_details[0]['index'])\n",
        "  if i==0:\n",
        "    tflite_model_predictions_test=Mod_Prediction\n",
        "  else:\n",
        "    tflite_model_predictions_test=np.concatenate((tflite_model_predictions_test,Mod_Prediction),axis=0)\n",
        "  print(i,\"Done\")\n",
        "\n",
        "acc_ = accuracy_score(np.argmax(tflite_model_predictions_test,axis=1), y_test[:len(tflite_model_predictions_test)])\n",
        "print('Test accuracy TFLITE model :', acc_)\n",
        "\n",
        "del X_test\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "C4_Z_BjLqTeL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c341e8-2097-4a2d-af46-1f9369882c3f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Done\n",
            "1 Done\n",
            "2 Done\n",
            "3 Done\n",
            "4 Done\n",
            "Test accuracy TFLITE model : 0.9698\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4081"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(NB_CLASSES):\n",
        "  variable_name = f\"Mean_{i}\"\n",
        "  locals()[variable_name]=np.array([0] * NB_CLASSES)\n",
        "\n",
        "print(X_train.shape)\n",
        "X_train=np.squeeze(X_train, axis=-1)\n",
        "X_valid=np.squeeze(X_valid, axis=-1)\n",
        "print(X_train.shape)\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "  X_train[i] = X_train[i] / input_scale + input_zero_point\n",
        "\n",
        "X_train = X_train[:, :,np.newaxis]\n",
        "X_train = X_train.astype('int8')\n",
        "\n",
        "# interpreter = tf.lite.Interpreter(model_path = tflite_model_name)\n",
        "# input_details = interpreter.get_input_details()\n",
        "# output_details = interpreter.get_output_details()\n",
        "# interpreter.resize_tensor_input(input_details[0]['index'], (Block, LENGTH, 1))\n",
        "# interpreter.resize_tensor_input(output_details[0]['index'], (Block, NB_CLASSES))\n",
        "# interpreter.allocate_tensors()\n",
        "\n",
        "\n",
        "tflite_model_predictions = []\n",
        "for i in range(20):\n",
        "  interpreter.set_tensor(input_details[0]['index'], X_train[i*Block:(i+1)*Block])\n",
        "  interpreter.invoke()\n",
        "  Mod_Prediction=interpreter.get_tensor(output_details[0]['index'])\n",
        "  if i==0:\n",
        "    tflite_model_predictions=Mod_Prediction\n",
        "  else:\n",
        "    tflite_model_predictions=np.concatenate((tflite_model_predictions,Mod_Prediction),axis=0)\n",
        "  print(i,\"Done\")\n",
        "\n",
        "del X_train\n",
        "\n",
        "count=[0]*NB_CLASSES\n",
        "txt_O = \"Mean_{Class1:.0f}\"\n",
        "Means={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Means[txt_O.format(Class1=i)]=np.array([0]*NB_CLASSES)\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  k=np.argmax(tflite_model_predictions[i])\n",
        "  if (np.argmax(tflite_model_predictions[i])==y_train[i]):\n",
        "    Means[txt_O.format(Class1=y_train[i])]=Means[txt_O.format(Class1=y_train[i])]+tflite_model_predictions[i]\n",
        "    count[y_train[i]]+=1\n",
        "print(\"Counts: \",count)\n",
        "\n",
        "Mean_Vectors=[]\n",
        "for i in range(NB_CLASSES):\n",
        "  Means[txt_O.format(Class1=i)]=Means[txt_O.format(Class1=i)]/count[i]\n",
        "  Mean_Vectors.append(Means[txt_O.format(Class1=i)])\n",
        "\n",
        "Mean_vectors=np.array(Mean_Vectors)\n",
        "\n",
        "\n",
        "Mean_vectors = np.array(Mean_Vectors)\n",
        "np.save('/content/temp_variables/Mean_vectors.npy', Mean_vectors, allow_pickle=True)\n",
        "\n",
        "# interpreter = tf.lite.Interpreter(model_path = tflite_model_name)\n",
        "\n",
        "# input_details = interpreter.get_input_details()\n",
        "# output_details = interpreter.get_output_details()\n",
        "\n",
        "for i in range(len(X_valid)):\n",
        "  X_valid[i] = X_valid[i] / input_scale + input_zero_point\n",
        "\n",
        "# interpreter = tf.lite.Interpreter(model_path = tflite_model_name)\n",
        "# input_details = interpreter.get_input_details()\n",
        "# output_details = interpreter.get_output_details()\n",
        "# interpreter.resize_tensor_input(input_details[0]['index'], (Block, LENGTH, 1))\n",
        "# interpreter.resize_tensor_input(output_details[0]['index'], (Block, NB_CLASSES))\n",
        "# interpreter.allocate_tensors()\n",
        "\n",
        "X_valid = X_valid[:, :,np.newaxis]\n",
        "X_valid = X_valid.astype('int8')\n",
        "\n",
        "tflite_model_predictions = []\n",
        "for i in range(8):\n",
        "  interpreter.set_tensor(input_details[0]['index'], X_valid[i*Block:(i+1)*Block])\n",
        "  interpreter.invoke()\n",
        "  Mod_Prediction=interpreter.get_tensor(output_details[0]['index'])\n",
        "  if i==0:\n",
        "    tflite_model_predictions=Mod_Prediction\n",
        "  else:\n",
        "    tflite_model_predictions=np.concatenate((tflite_model_predictions,Mod_Prediction),axis=0)\n",
        "  print(i,\"Done\")\n",
        "\n",
        "del X_valid\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "rcNvdJzUqJ71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12dd99fc-4a27-42fd-d61e-f1d84958bcca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(76000, 1500, 1)\n",
            "(76000, 1500)\n",
            "0 Done\n",
            "1 Done\n",
            "2 Done\n",
            "3 Done\n",
            "4 Done\n",
            "5 Done\n",
            "6 Done\n",
            "7 Done\n",
            "8 Done\n",
            "9 Done\n",
            "10 Done\n",
            "11 Done\n",
            "12 Done\n",
            "13 Done\n",
            "14 Done\n",
            "15 Done\n",
            "16 Done\n",
            "17 Done\n",
            "18 Done\n",
            "19 Done\n",
            "Counts:  [232, 228, 221, 190, 198, 211, 210, 223, 200, 214, 186, 209, 231, 205, 218, 233, 199, 174, 179, 194, 201, 217, 212, 213, 212, 210, 215, 212, 208, 197, 217, 198, 198, 205, 227, 214, 205, 209, 213, 223, 216, 230, 199, 198, 183, 189, 249, 196, 198, 202, 199, 213, 195, 183, 205, 211, 192, 206, 182, 206, 223, 230, 192, 190, 186, 213, 205, 200, 227, 186, 188, 227, 190, 230, 199, 205, 188, 218, 214, 209, 230, 204, 214, 198, 211, 199, 196, 194, 200, 206, 214, 216, 206, 204, 196]\n",
            "0 Done\n",
            "1 Done\n",
            "2 Done\n",
            "3 Done\n",
            "4 Done\n",
            "5 Done\n",
            "6 Done\n",
            "7 Done\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "\n",
        "Indexes=[]\n",
        "for i in range(NB_CLASSES):\n",
        "  Indexes.append([])\n",
        "\n",
        "Values={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Values[i]=[0]*NB_CLASSES\n",
        "\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]):\n",
        "        Values[y_valid[i]][k]+=np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])-dist\n",
        "\n",
        "for i in range(NB_CLASSES):\n",
        "  Tot=0\n",
        "  for l in range(30):\n",
        "      Min=min(Values[i])\n",
        "      Tot+=Min\n",
        "      Indexes[i].append(Values[i].index(Min))\n",
        "      Values[i][Values[i].index(Min)]=np.inf\n",
        "\n",
        "Indexes=np.array(Indexes)\n",
        "\n",
        "np.save('/content/temp_variables/Values.npy',np.array(Values))\n",
        "np.save('/content/temp_variables/Indexes.npy',Indexes)\n",
        "\n",
        "print()\n",
        "##################################################################################################\n",
        "print()\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(dist)\n",
        "\n",
        "\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.8)]\n",
        "\n",
        "\n",
        "\n",
        "Threasholds_1=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_1.npy',Threasholds_1)\n",
        "print(\"Thresholds for method 1 calculated\")\n",
        "##################################################################################################\n",
        "print()\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]) and k in Indexes[y_valid[i]]:\n",
        "        Tot+=(np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])-dist)\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(Tot)\n",
        "\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.8)]\n",
        "\n",
        "\n",
        "\n",
        "Threasholds_2=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_2.npy',Threasholds_2)\n",
        "\n",
        "\n",
        "print(\"Thresholds for method 2 calculated\")\n",
        "\n",
        "##################################################################################################\n",
        "print()\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]) and k in Indexes[y_valid[i]]:\n",
        "        Tot+=np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])\n",
        "    Tot=dist/Tot\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(Tot)\n",
        "\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.2)]\n",
        "\n",
        "Threasholds_3=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_3.npy',Threasholds_3)\n",
        "print(\"Thresholds for method 3 calculated\")"
      ],
      "metadata": {
        "id": "k4crCfkxrAbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8feca0a5-b307-4824-ba37-15db7f189241"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Thresholds for method 1 calculated\n",
            "\n",
            "Thresholds for method 2 calculated\n",
            "\n",
            "Thresholds for method 3 calculated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(len(X_open)):\n",
        "  X_open[i] = X_open[i] / input_scale + input_zero_point\n",
        "\n",
        "X_open = X_open[:, :,np.newaxis]\n",
        "X_open = X_open.astype('int8')\n",
        "\n",
        "for i in range(10):\n",
        "  interpreter.set_tensor(input_details[0]['index'], X_open[i*Block:(i+1)*Block])\n",
        "  interpreter.invoke()\n",
        "  Mod_Prediction=interpreter.get_tensor(output_details[0]['index'])\n",
        "  if i==0:\n",
        "    tflite_model_predictions_open=Mod_Prediction\n",
        "  else:\n",
        "    tflite_model_predictions_open=np.concatenate((tflite_model_predictions,Mod_Prediction),axis=0)\n",
        "  print(i,\"Done\")\n",
        "\n",
        "del X_open\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Jt_HrJs-HYon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff06559-844d-49b8-a481-0d25d01b899b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Done\n",
            "1 Done\n",
            "2 Done\n",
            "3 Done\n",
            "4 Done\n",
            "5 Done\n",
            "6 Done\n",
            "7 Done\n",
            "8 Done\n",
            "9 Done\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"############## Distance Method 1 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    if np.linalg.norm(tflite_model_predictions_test[i]-Mean_vectors[d])>Threasholds_1[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    if np.linalg.norm(tflite_model_predictions_open[i]-Mean_vectors[d])>=Threasholds_1[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "y_test=y_test[:len(prediction_classes)]\n",
        "y_open=y_open[:len(prediction_classes_open)]\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "print(\"Average novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################################################\n",
        "print()\n",
        "print(\"############## Distance Method 2 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_test[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=d:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_test[i])-dist\n",
        "\n",
        "    if Tot<Threasholds_2[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    dist = np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_open[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(d) and k in Indexes[d]:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_open[i])-dist\n",
        "\n",
        "    if Tot<=Threasholds_2[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "\n",
        "print(\"Average Novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################################################\n",
        "print()\n",
        "print(\"############## Distance Method 3 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_test[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=d:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_test[i])\n",
        "\n",
        "    Tot=dist/Tot\n",
        "    if Tot>Threasholds_3[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_open[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(d) and k in Indexes[d]:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_open[i])\n",
        "    Tot=dist/Tot\n",
        "    if Tot>=Threasholds_3[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "\n",
        "print(\"Average Novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)"
      ],
      "metadata": {
        "id": "_CLDbBIeHZhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246b0e37-757f-45bd-8676-313a3b7d6eab"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############## Distance Method 1 #################################\n",
            "\n",
            "Test accuracy Normal model_Closed_set : 0.7674\n",
            "Test accuracy Normal model_Open_set : 0.3011111111111111\n",
            "Precision:  0.08470342553746821\n",
            "Recall:  0.7780478682812901\n",
            "Average novel F1_Score:  0.15277477851113094\n",
            "\n",
            "Micro\n",
            "Micro Precision:  0.37799231602797756\n",
            "Micro Recall:  0.7674\n",
            "Average Micro F1_Score:  0.5065012166194391\n",
            "\n",
            "Macro\n",
            "Precision: 0.2807213712858705\n",
            "Recall: 0.40389473680171584\n",
            "Average Macro F1_Score:  0.33122762194628286\n",
            "\n",
            "############## Distance Method 2 #################################\n",
            "\n",
            "Test accuracy Normal model_Closed_set : 0.9636\n",
            "Test accuracy Normal model_Open_set : 0.8333333333333334\n",
            "Precision:  0.7131505756252009\n",
            "Recall:  0.9663934425242271\n",
            "Average Novel F1_Score:  0.8206799324885049\n",
            "\n",
            "Micro\n",
            "Micro Precision:  0.7480204937121565\n",
            "Micro Recall:  0.9636\n",
            "Average Micro F1_Score:  0.8422340655277052\n",
            "\n",
            "Macro\n",
            "Precision: 0.44640953025033886\n",
            "Recall: 0.5071578946861264\n",
            "Average Macro F1_Score:  0.4748486771565751\n",
            "\n",
            "############## Distance Method 3 #################################\n",
            "\n",
            "Test accuracy Normal model_Closed_set : 0.9404\n",
            "Test accuracy Normal model_Open_set : 0.8313333333333334\n",
            "Precision:  0.7094355067743006\n",
            "Recall:  0.9442597637544745\n",
            "Average Novel F1_Score:  0.8101751415914265\n",
            "\n",
            "Micro\n",
            "Micro Precision:  0.7459939711248612\n",
            "Micro Recall:  0.9404\n",
            "Average Micro F1_Score:  0.8319915017460892\n",
            "\n",
            "Macro\n",
            "Precision: 0.44646288403021994\n",
            "Recall: 0.4949473683715579\n",
            "Average Macro F1_Score:  0.4694565979397084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Wt-p1khKa8o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}