{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enm9BtN2Uonx",
        "outputId": "e87aa639-87a9-4b7a-b4f6-0ebbfe0b12ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SFdnbZgRVmv",
        "outputId": "d8c9ae41-a9c1-4204-8cb6-36ee8666e737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/DF_dataset.zip\n",
            "  inflating: /content/dataset/X_test_NoDef.pkl  \n",
            "  inflating: /content/dataset/X_train_NoDef.pkl  \n",
            "  inflating: /content/dataset/X_valid_NoDef.pkl  \n",
            "  inflating: /content/dataset/y_test_NoDef.pkl  \n",
            "  inflating: /content/dataset/y_train_NoDef.pkl  \n",
            "  inflating: /content/dataset/y_valid_NoDef.pkl  \n",
            "  inflating: /content/dataset/ziping.py  \n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "directory = \"/content/dataset\"\n",
        "if any(os.listdir(directory)):\n",
        "  print('dataset exists')\n",
        "else:\n",
        "  !unzip /content/DF_dataset -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "hYBY7tdaaTEC",
        "outputId": "244c6c08-a313-4c7d-a422-039b1f728516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15D1vov_iXPWMpGO6-xnb-M6aDXWPxtHD\n",
            "To: /content/X_test_Unmon_NoDef.pkl\n",
            "100% 801M/801M [00:08<00:00, 90.6MB/s]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3441afc2d130>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gdown 15D1vov_iXPWMpGO6-xnb-M6aDXWPxtHD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmv\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mX_test_Unmon_NoDef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpkl\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mopenset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'mv' is not defined"
          ]
        }
      ],
      "source": [
        "!gdown 15D1vov_iXPWMpGO6-xnb-M6aDXWPxtHD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ftMzrePpvG-n"
      },
      "outputs": [],
      "source": [
        "mv /content/X_test_Unmon_NoDef.pkl /content/dataset/openset.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PM1cPJ_soczA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from utility import LoadDataIot\n",
        "from Model_NoDef import DFNet_Robust\n",
        "import random\n",
        "import tensorflow\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "from sklearn.metrics import accuracy_score\n",
        "np_config.enable_numpy_behavior()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1xfCexiTEtKt"
      },
      "outputs": [],
      "source": [
        "def representative_data_gen_Open():\n",
        "  for input_value in tf.data.Dataset.from_tensor_slices(X__open).batch(1).take(1000):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size\n",
        "\n",
        "def convert_bytes(size, unit=None):\n",
        "    if unit == \"KB\":\n",
        "        return str(round(size / 1024, 3))\n",
        "    elif unit == \"MB\":\n",
        "        return str(round(size / (1024 * 1024), 3))\n",
        "    else:\n",
        "        return str(size)\n",
        "\n",
        "\n",
        "def Micro_F1(matrix):\n",
        "    epsilon = 1e-8\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "\n",
        "    for k in range(NB_CLASSES):\n",
        "        TP += matrix[k][k]\n",
        "        FP += (np.sum(Matrix, axis=0)[k] - matrix[k][k])\n",
        "        TN += (np.sum(Matrix, axis=1)[k] - matrix[k][k])\n",
        "\n",
        "    Micro_Prec = TP / (TP + FP)\n",
        "    Micro_Rec = TP / (TP + TN)\n",
        "    print(\"Micro Precision: \", Micro_Prec)\n",
        "    print(\"Micro Recall: \", Micro_Rec)\n",
        "    Micro_F1 = 2 * Micro_Prec * Micro_Rec / (Micro_Rec + Micro_Prec + epsilon)\n",
        "\n",
        "    return Micro_F1\n",
        "\n",
        "\n",
        "def New_F1_Score(Matrix):\n",
        "    epsilon = 1e-8\n",
        "    Column_sum = np.sum(Matrix, axis=0)\n",
        "    Raw_sum = np.sum(Matrix, axis=1)\n",
        "\n",
        "    Precision_Differences = []\n",
        "    Recall_Differences = []\n",
        "    for i in range(NB_CLASSES):\n",
        "        Precision_Differences.append(np.abs(2 * Matrix[i][i] - Column_sum[i]))\n",
        "        Recall_Differences.append(np.abs(2 * Matrix[i][i] - Raw_sum[i]))\n",
        "\n",
        "    Precision_Differences = np.array(Precision_Differences)\n",
        "    Precision_Differences_Per = Precision_Differences / (np.sum(Precision_Differences)+epsilon)\n",
        "    Recall_Differences = np.array(Recall_Differences)\n",
        "    Recall_Differences_Per = Recall_Differences / (np.sum(Recall_Differences)+epsilon)\n",
        "\n",
        "    # print('Precision_Differences_Per',Precision_Differences_Per)\n",
        "    # print('Recall_Differences_Per',Recall_Differences_Per)\n",
        "\n",
        "    Precisions = np.zeros(NB_CLASSES)\n",
        "    Recalls = np.zeros(NB_CLASSES)\n",
        "\n",
        "    for k in range(len(Precisions)):\n",
        "        Precisions[k] = (Matrix[k][k] / np.sum(Matrix, axis=0)[k])\n",
        "    Precision = np.sum(np.array(Precisions) * Precision_Differences_Per)\n",
        "\n",
        "    for k in range(len(Recalls)):\n",
        "        Recalls[k] = Matrix[k][k] / (np.sum(Matrix, axis=1)[k]+ epsilon)  # *Recall_Differences_Per[k]\n",
        "    Recall = np.sum(np.array(Recalls) * Recall_Differences_Per)\n",
        "\n",
        "    print('Precision: ', Precision)\n",
        "    print('Recall: ', Recall)\n",
        "\n",
        "    F1_Score = 2 * Precision * Recall / (Precision + Recall + epsilon)\n",
        "    return F1_Score\n",
        "\n",
        "\n",
        "def Macro_F1(Matrix):\n",
        "    Precisions = np.zeros(NB_CLASSES)\n",
        "    Recalls = np.zeros(NB_CLASSES)\n",
        "\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    for k in range(len(Precisions)):\n",
        "        Precisions[k] = Matrix[k][k] / (np.sum(Matrix, axis=0)[k]+epsilon)\n",
        "    # print(Precisions)\n",
        "\n",
        "    Precision = np.average(Precisions)\n",
        "    print(\"Precision:\", Precision)\n",
        "\n",
        "    for k in range(len(Recalls)):\n",
        "        Recalls[k] = Matrix[k][k] / (np.sum(Matrix, axis=1)[k]+epsilon)\n",
        "\n",
        "    Recall = np.average(Recalls)\n",
        "    print(\"Recall:\", Recall)\n",
        "\n",
        "    F1_Score = 2 * Precision * Recall / (Precision + Recall + epsilon)\n",
        "    return F1_Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c47F0U2wuYf",
        "outputId": "17d000ec-19e8-4590-ad2d-3c8df6a20f0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm1lT_mRXJwD",
        "outputId": "3f064b23-10f4-46df-da55-2fdfcd4cc5ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Epoch:  10\n",
            "Loading and preparing data for training, and evaluating the model\n",
            "Data dimensions:\n",
            "X: Training data's shape :  (76000, 1500)\n",
            "y: Training data's shape :  (76000,)\n",
            "X: Validation data's shape :  (9500, 1500)\n",
            "y: Validation data's shape :  (9500,)\n",
            "X: Testing data's shape :  (9500, 1500)\n",
            "y: Testing data's shape :  (9500,)\n"
          ]
        }
      ],
      "source": [
        "NB_EPOCH = 10   # Number of training epoch\n",
        "print (\"Number of Epoch: \", NB_EPOCH)\n",
        "BATCH_SIZE = 128 # Batch size\n",
        "VERBOSE = 2 # Output display mode\n",
        "LENGTH = 1500 # Packet sequence length\n",
        "OPTIMIZER = Adamax(learning_rate=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08) # Optimizer\n",
        "\n",
        "NB_CLASSES = 95 # number of outputs = number of classes\n",
        "INPUT_SHAPE = (LENGTH,1)\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "print (\"Loading and preparing data for training, and evaluating the model\")\n",
        "X_train, y_train, X_valid, y_valid, X_test, y_test = LoadDataIot()\n",
        "\n",
        "# Convert data as float32 type\n",
        "X_train = X_train.astype('float32')\n",
        "X_valid = X_valid.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "y_valid = y_valid.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "\n",
        "# we need a [Length x 1] x n shape as input to the DF CNN (Tensorflow)\n",
        "X_train = X_train[:, :,np.newaxis]\n",
        "X_valid = X_valid[:, :,np.newaxis]\n",
        "X_test = X_test[:, :,np.newaxis]\n",
        "\n",
        "# Convert class vectors to categorical classes matrices\n",
        "y_train = to_categorical(y_train, NB_CLASSES)\n",
        "y_valid = to_categorical(y_valid, NB_CLASSES)\n",
        "y_test = to_categorical(y_test, NB_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHtdjBU9qAnu",
        "outputId": "6d2b4f4a-ab9b-4021-bef1-881586281ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model compiled\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.74053, saving model to /content/trained_models/DF.hdf5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "594/594 - 49s - loss: 2.4749 - accuracy: 0.3788 - val_loss: 0.9709 - val_accuracy: 0.7405 - 49s/epoch - 82ms/step\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.74053 to 0.88053, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 27s - loss: 1.0010 - accuracy: 0.7372 - val_loss: 0.4515 - val_accuracy: 0.8805 - 27s/epoch - 45ms/step\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.88053 to 0.93189, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 27s - loss: 0.6173 - accuracy: 0.8423 - val_loss: 0.2748 - val_accuracy: 0.9319 - 27s/epoch - 46ms/step\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.93189 to 0.93821, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 28s - loss: 0.4548 - accuracy: 0.8838 - val_loss: 0.2373 - val_accuracy: 0.9382 - 28s/epoch - 46ms/step\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.93821 to 0.95084, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 28s - loss: 0.3589 - accuracy: 0.9089 - val_loss: 0.1845 - val_accuracy: 0.9508 - 28s/epoch - 46ms/step\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.95084 to 0.95347, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 27s - loss: 0.2967 - accuracy: 0.9254 - val_loss: 0.1800 - val_accuracy: 0.9535 - 27s/epoch - 46ms/step\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.95347 to 0.95979, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 27s - loss: 0.2571 - accuracy: 0.9357 - val_loss: 0.1535 - val_accuracy: 0.9598 - 27s/epoch - 46ms/step\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.95979 to 0.96253, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 27s - loss: 0.2263 - accuracy: 0.9425 - val_loss: 0.1478 - val_accuracy: 0.9625 - 27s/epoch - 46ms/step\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96253\n",
            "594/594 - 28s - loss: 0.1972 - accuracy: 0.9493 - val_loss: 0.1474 - val_accuracy: 0.9622 - 28s/epoch - 47ms/step\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.96253 to 0.96947, saving model to /content/trained_models/DF.hdf5\n",
            "594/594 - 28s - loss: 0.1751 - accuracy: 0.9558 - val_loss: 0.1246 - val_accuracy: 0.9695 - 28s/epoch - 47ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "297/297 - 2s - loss: 16.0157 - accuracy: 0.9701 - 2s/epoch - 8ms/step\n",
            "Testing closed accuracy_without_norm: 0.9701052904129028\n"
          ]
        }
      ],
      "source": [
        "model = DFNet_Robust.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "print (\"Model compiled\")\n",
        "\n",
        "filepath = '/content/trained_models/DF.hdf5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Start training\n",
        "history = model.fit(X_train, y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "\t\tverbose=VERBOSE, validation_data=(X_valid, y_valid), callbacks=callbacks_list)\n",
        "\n",
        "#Start evaluating model with testing data\n",
        "\n",
        "model_penultimate = Model(model.input, model.layers[-2].output)\n",
        "model_penultimate.save('/content/trained_models/DF_without_softmax.hdf5')\n",
        "model_penultimate.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "score_test = model_penultimate.evaluate(X_test, y_test, verbose=VERBOSE)\n",
        "print(\"Testing closed accuracy_without_norm:\", score_test[1])\n",
        "\n",
        "del model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUs0iOSobKOz",
        "outputId": "5644da5d-39e4-4b1b-e777-6648b9ea2b4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20000, 1500)\n"
          ]
        }
      ],
      "source": [
        "import _pickle as cPickle\n",
        "dataset_dir = \"/content/dataset/\"\n",
        "with open( dataset_dir+\"openset.pkl\",\"rb\") as f:\n",
        "        X_open = cPickle.load(f,encoding='latin1')\n",
        "X_open = np.array(X_open)\n",
        "X_open=X_open[:,:1500]\n",
        "print(X_open.shape)\n",
        "X_open = X_open.astype('float32')\n",
        "X_open = X_open[:,:,np.newaxis]\n",
        "y_open = np.array([NB_CLASSES]*len(X_open))\n",
        "y_open = y_open.astype('int8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4_Z_BjLqTeL",
        "outputId": "083a7a3c-5362-4049-cf83-450ffc74d439"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "297/297 [==============================] - 2s 4ms/step\n",
            "Test accuracy TFLITE model : 0.9701052631578947\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3297"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def representative_data_gen():\n",
        "  for input_value in tensorflow.data.Dataset.from_tensor_slices(X_train_Rep).batch(1).take(100):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "\n",
        "y_train=np.argmax(y_train, axis=1)\n",
        "y_valid=np.argmax(y_valid, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "tflite_model_predictions_test=model_penultimate.predict(X_test)\n",
        "\n",
        "acc_ = accuracy_score(np.argmax(tflite_model_predictions_test,axis=1), y_test[:len(tflite_model_predictions_test)])\n",
        "print('Test accuracy TFLITE model :', acc_)\n",
        "\n",
        "del X_test\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcNvdJzUqJ71",
        "outputId": "2ba6449f-a8fc-4da8-9b0d-ae17b04b4e74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2375/2375 [==============================] - 10s 4ms/step\n",
            "Counts:  [777, 794, 794, 787, 792, 786, 766, 798, 793, 794, 792, 794, 791, 788, 784, 793, 792, 783, 780, 795, 790, 784, 785, 794, 790, 798, 799, 778, 791, 787, 797, 796, 794, 794, 783, 757, 778, 771, 796, 793, 795, 796, 793, 794, 794, 779, 798, 761, 798, 773, 788, 797, 799, 750, 775, 791, 786, 790, 706, 795, 792, 790, 761, 785, 766, 787, 795, 776, 798, 798, 781, 790, 773, 794, 797, 798, 763, 782, 786, 778, 787, 788, 772, 790, 786, 795, 776, 771, 788, 780, 797, 779, 794, 784, 772]\n",
            "297/297 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1408"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "for i in range(NB_CLASSES):\n",
        "  variable_name = f\"Mean_{i}\"\n",
        "  locals()[variable_name]=np.array([0] * NB_CLASSES)\n",
        "\n",
        "tflite_model_predictions=model_penultimate.predict(X_train)\n",
        "\n",
        "del X_train\n",
        "\n",
        "count=[0]*NB_CLASSES\n",
        "txt_O = \"Mean_{Class1:.0f}\"\n",
        "Means={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Means[txt_O.format(Class1=i)]=np.array([0]*NB_CLASSES)\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  k=np.argmax(tflite_model_predictions[i])\n",
        "  if (np.argmax(tflite_model_predictions[i])==y_train[i]):\n",
        "    Means[txt_O.format(Class1=y_train[i])]=Means[txt_O.format(Class1=y_train[i])]+tflite_model_predictions[i]\n",
        "    count[y_train[i]]+=1\n",
        "print(\"Counts: \",count)\n",
        "\n",
        "Mean_Vectors=[]\n",
        "for i in range(NB_CLASSES):\n",
        "  Means[txt_O.format(Class1=i)]=Means[txt_O.format(Class1=i)]/count[i]\n",
        "  Mean_Vectors.append(Means[txt_O.format(Class1=i)])\n",
        "\n",
        "Mean_vectors=np.array(Mean_Vectors)\n",
        "\n",
        "\n",
        "Mean_vectors = np.array(Mean_Vectors)\n",
        "np.save('/content/temp_variables/Mean_vectors.npy', Mean_vectors, allow_pickle=True)\n",
        "\n",
        "tflite_model_predictions=model_penultimate.predict(X_valid)\n",
        "\n",
        "del X_valid\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4crCfkxrAbN",
        "outputId": "b7394286-4961-4a52-bf53-f60ec9125176"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Thresholds for method 1 calculated\n",
            "\n",
            "Thresholds for method 2 calculated\n",
            "\n",
            "Thresholds for method 3 calculated\n"
          ]
        }
      ],
      "source": [
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "\n",
        "Indexes=[]\n",
        "for i in range(NB_CLASSES):\n",
        "  Indexes.append([])\n",
        "\n",
        "Values={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Values[i]=[0]*NB_CLASSES\n",
        "\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]):\n",
        "        Values[y_valid[i]][k]+=np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])-dist\n",
        "\n",
        "for i in range(NB_CLASSES):\n",
        "  Tot=0\n",
        "  for l in range(50):\n",
        "      Min=min(Values[i])\n",
        "      Tot+=Min\n",
        "      Indexes[i].append(Values[i].index(Min))\n",
        "      Values[i][Values[i].index(Min)]=1000000\n",
        "\n",
        "Indexes=np.array(Indexes)\n",
        "\n",
        "np.save('/content/temp_variables/Values.npy',np.array(Values))\n",
        "np.save('/content/temp_variables/Indexes.npy',Indexes)\n",
        "\n",
        "print()\n",
        "##################################################################################################\n",
        "print()\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(dist)\n",
        "\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.9)]\n",
        "\n",
        "\n",
        "\n",
        "Threasholds_1=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_1.npy',Threasholds_1)\n",
        "print(\"Thresholds for method 1 calculated\")\n",
        "##################################################################################################\n",
        "print()\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]) and k in Indexes[y_valid[i]]:\n",
        "        Tot+=(np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])-dist)\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(Tot)\n",
        "\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.1)]\n",
        "\n",
        "\n",
        "\n",
        "Threasholds_2=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_2.npy',Threasholds_2)\n",
        "\n",
        "\n",
        "print(\"Thresholds for method 2 calculated\")\n",
        "\n",
        "##################################################################################################\n",
        "print()\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]) and k in Indexes[y_valid[i]]:\n",
        "        Tot+=np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])\n",
        "    Tot=dist/Tot\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(Tot)\n",
        "\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.9)]\n",
        "\n",
        "Threasholds_3=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_3.npy',Threasholds_3)\n",
        "print(\"Thresholds for method 3 calculated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt_HrJs-HYon",
        "outputId": "a764dfe0-4de5-4507-a09c-33e098a551ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 4s 6ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "686"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "############################################################################################\n",
        "\n",
        "######################## Evaluating results ##########################\n",
        "tflite_model_predictions_open=model_penultimate.predict(X_open)\n",
        "\n",
        "del X_open\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CLDbBIeHZhb",
        "outputId": "b8de05ab-5772-4d45-9ccb-4f5606637cc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "############## Distance Method 1 #################################\n",
            "\n",
            "Test accuracy Normal model_Closed_set : 0.8758947368421053\n",
            "Test accuracy Normal model_Open_set : 0.82\n",
            "Precision:  0.763605853682793\n",
            "Recall:  0.8826127135256231\n",
            "Average novel F1_Score:  0.81880771352478\n",
            "\n",
            "Micro\n",
            "Micro Precision:  0.693127863390254\n",
            "Micro Recall:  0.8758947368421053\n",
            "Average Micro F1_Score:  0.7738665377323399\n",
            "\n",
            "Macro\n",
            "Precision: 0.8514747759667909\n",
            "Recall: 0.8758947368421052\n",
            "Average Macro F1_Score:  0.8635121379360275\n",
            "\n",
            "############## Distance Method 2 #################################\n",
            "\n",
            "Test accuracy Normal model_Closed_set : 0.9637894736842105\n",
            "Test accuracy Normal model_Open_set : 0.85545\n",
            "Precision:  0.8079727909493953\n",
            "Recall:  0.9662006354970495\n",
            "Average Novel F1_Score:  0.8800310139275335\n",
            "\n",
            "Micro\n",
            "Micro Precision:  0.7456026058631922\n",
            "Micro Recall:  0.9637894736842105\n",
            "Average Micro F1_Score:  0.8407713449437189\n",
            "\n",
            "Macro\n",
            "Precision: 0.8804551660715125\n",
            "Recall: 0.9637894736842105\n",
            "Average Macro F1_Score:  0.9202395367913946\n",
            "\n",
            "############## Distance Method 3 #################################\n",
            "\n",
            "Test accuracy Normal model_Closed_set : 0.9671578947368421\n",
            "Test accuracy Normal model_Open_set : 0.85145\n",
            "Precision:  0.8039463957785781\n",
            "Recall:  0.9694547093285262\n",
            "Average Novel F1_Score:  0.8789772520112199\n",
            "\n",
            "Micro\n",
            "Micro Precision:  0.739893702689644\n",
            "Micro Recall:  0.9671578947368421\n",
            "Average Micro F1_Score:  0.8383976591090613\n",
            "\n",
            "Macro\n",
            "Precision: 0.8753626885388095\n",
            "Recall: 0.9671578947368422\n",
            "Average Macro F1_Score:  0.9189736473699416\n"
          ]
        }
      ],
      "source": [
        "print()\n",
        "print(\"############## Distance Method 1 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    if np.linalg.norm(tflite_model_predictions_test[i]-Mean_vectors[d])>Threasholds_1[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    if np.linalg.norm(tflite_model_predictions_open[i]-Mean_vectors[d])>Threasholds_1[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "y_test=y_test[:len(prediction_classes)]\n",
        "y_open=y_open[:len(prediction_classes_open)]\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "print(\"Average novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################################################\n",
        "print()\n",
        "print(\"############## Distance Method 2 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_test[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=d:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_test[i])-dist\n",
        "\n",
        "    if Tot<Threasholds_2[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    dist = np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_open[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(d) and k in Indexes[d]:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_open[i])-dist\n",
        "\n",
        "    if Tot<Threasholds_2[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "\n",
        "print(\"Average Novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################################################\n",
        "print()\n",
        "print(\"############## Distance Method 3 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_test[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=d:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_test[i])\n",
        "\n",
        "    Tot=dist/Tot\n",
        "    if Tot>Threasholds_3[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_open[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(d) and k in Indexes[d]:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_open[i])\n",
        "    Tot=dist/Tot\n",
        "    if Tot>Threasholds_3[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "\n",
        "print(\"Average Novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Wt-p1khKa8o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
