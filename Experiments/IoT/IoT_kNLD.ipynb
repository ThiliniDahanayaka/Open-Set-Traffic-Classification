{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8qni45cchoG",
        "outputId": "12fd30b2-60fd-48c6-c6de-3d00781bccc3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PM1cPJ_soczA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from utility import LoadDataIot\n",
        "from IOT_CNN import DFNet_Dropout  #DFNet_Add_Layer\n",
        "import random\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "from sklearn.metrics import accuracy_score\n",
        "np_config.enable_numpy_behavior()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python dataset/IoT_Class_filter.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmD_ZayDwZKk",
        "outputId": "260cc756-f0a3-4630-f139-04bdb24ed990"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-02-14 07:17:52.818649: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-14 07:17:52.818706: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-14 07:17:52.820387: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-14 07:17:54.620411: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Data dimensions:\n",
            "X: Training data's shape :  (41898, 475)\n",
            "X: Validating data's shape :  (10774, 475)\n",
            "X: Testing data's shape :  (7183, 475)\n",
            "X: open data's shape :  (86886, 475)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NB_EPOCH = 40   # Number of training epoch\n",
        "print (\"Number of Epoch: \", NB_EPOCH)\n",
        "BATCH_SIZE = 70 # Batch size\n",
        "VERBOSE = 2 # Output display mode\n",
        "LENGTH = 475 # Packet sequence length\n",
        "\n",
        "\n",
        "OPTIMIZER = Adamax(learning_rate=0.05, beta_1=0.9, beta_2=0.999, epsilon=1e-08) # Optimizer\n",
        "\n",
        "NB_CLASSES = 40 # number of outputs = number of classes\n",
        "INPUT_SHAPE = (LENGTH,1)\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "def representative_data_gen():\n",
        "  for input_value in tensorflow.data.Dataset.from_tensor_slices(X_train_Rep).batch(1).take(100):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "\n",
        "def Micro_F1(matrix):\n",
        "    epsilon = 1e-8\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "\n",
        "    for k in range(NB_CLASSES):\n",
        "        TP += matrix[k][k]\n",
        "        FP += (np.sum(Matrix, axis=0)[k] - matrix[k][k])\n",
        "        TN += (np.sum(Matrix, axis=1)[k] - matrix[k][k])\n",
        "\n",
        "    Micro_Prec = TP / (TP + FP)\n",
        "    Micro_Rec = TP / (TP + TN)\n",
        "    print(\"Micro Precision: \", Micro_Prec)\n",
        "    print(\"Micro Recall: \", Micro_Rec)\n",
        "    Micro_F1 = 2 * Micro_Prec * Micro_Rec / (Micro_Rec + Micro_Prec + epsilon)\n",
        "\n",
        "    return Micro_F1\n",
        "\n",
        "\n",
        "def New_F1_Score(Matrix):\n",
        "    Column_sum = np.sum(Matrix, axis=0)\n",
        "    Raw_sum = np.sum(Matrix, axis=1)\n",
        "\n",
        "    Precision_Differences = []\n",
        "    Recall_Differences = []\n",
        "    for i in range(NB_CLASSES):\n",
        "        Precision_Differences.append(np.abs(2 * Matrix[i][i] - Column_sum[i]))\n",
        "        Recall_Differences.append(np.abs(2 * Matrix[i][i] - Raw_sum[i]))\n",
        "\n",
        "    Precision_Differences = np.array(Precision_Differences)\n",
        "    Precision_Differences_Per = Precision_Differences / np.sum(Precision_Differences)\n",
        "    Recall_Differences = np.array(Recall_Differences)\n",
        "    Recall_Differences_Per = Recall_Differences / np.sum(Recall_Differences)\n",
        "\n",
        "    # print('Precision_Differences_Per',Precision_Differences_Per)\n",
        "    # print('Recall_Differences_Per',Recall_Differences_Per)\n",
        "\n",
        "    Precisions = np.zeros(NB_CLASSES)\n",
        "    Recalls = np.zeros(NB_CLASSES)\n",
        "\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    for k in range(len(Precisions)):\n",
        "        Precisions[k] = (Matrix[k][k] / np.sum(Matrix, axis=0)[k])\n",
        "    Precision = np.sum(np.array(Precisions) * Precision_Differences_Per)\n",
        "\n",
        "    for k in range(len(Recalls)):\n",
        "        Recalls[k] = (Matrix[k][k] / np.sum(Matrix, axis=1)[k])  # *Recall_Differences_Per[k]\n",
        "    Recall = np.sum(np.array(Recalls) * Recall_Differences_Per)\n",
        "\n",
        "    print('Precision: ', Precision)\n",
        "    print('Recall: ', Recall)\n",
        "\n",
        "    F1_Score = 2 * Precision * Recall / (Precision + Recall + epsilon)\n",
        "    return F1_Score\n",
        "\n",
        "\n",
        "def Macro_F1(Matrix):\n",
        "    Precisions = np.zeros(NB_CLASSES)\n",
        "    Recalls = np.zeros(NB_CLASSES)\n",
        "\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    for k in range(len(Precisions)):\n",
        "        Precisions[k] = Matrix[k][k] / np.sum(Matrix, axis=0)[k]\n",
        "    # print(Precisions)\n",
        "\n",
        "    Precision = np.average(Precisions)\n",
        "    print(\"Precision:\", Precision)\n",
        "\n",
        "    for k in range(len(Recalls)):\n",
        "        Recalls[k] = Matrix[k][k] / np.sum(Matrix, axis=1)[k]\n",
        "\n",
        "    Recall = np.average(Recalls)\n",
        "    print(\"Recall:\", Recall)\n",
        "\n",
        "    F1_Score = 2 * Precision * Recall / (Precision + Recall + epsilon)\n",
        "    return F1_Score\n",
        "\n",
        "print (\"Loading and preparing data for training, and evaluating the model\")\n",
        "X_train, y_train, X_valid, y_valid, X_test, y_test = LoadDataIot()\n",
        "# Please refer to the dataset format in readme\n",
        "\n",
        "# Convert data as float32 type\n",
        "X_train = X_train.astype('float32')\n",
        "X_valid = X_valid.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "y_valid = y_valid.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "# we need a [Length x 1] x n shape as input to the DF CNN (Tensorflow)\n",
        "X_train = X_train[:, :,np.newaxis]\n",
        "X_valid = X_valid[:, :,np.newaxis]\n",
        "X_test = X_test[:, :,np.newaxis]\n",
        "\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_valid.shape[0], 'validation samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to categorical classes matrices\n",
        "y_train = to_categorical(y_train, NB_CLASSES)\n",
        "y_valid = to_categorical(y_valid, NB_CLASSES)\n",
        "y_test = to_categorical(y_test, NB_CLASSES)\n",
        "# Building and training model\n",
        "# print (\"Building and training DF model\")\n",
        "\n",
        "model = DFNet_Dropout.build(input_shape=INPUT_SHAPE, nb_classes=NB_CLASSES)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "print (\"Model compiled\")\n",
        "\n",
        "filepath = '/content/trained_models/IoT.hdf5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Start training\n",
        "history = model.fit(X_train, y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "\t\tverbose=VERBOSE, validation_data=(X_valid, y_valid), callbacks=callbacks_list)\n",
        "\n",
        "# Start evaluating model with testing data\n",
        "score_test = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
        "print(\"Testing closed accuracy_without_norm:\", score_test[1])\n",
        "\n",
        "model_penultimate = Model(model.input, model.layers[-2].output)\n",
        "model_penultimate.save('/content/trained_models/IoT_without_softmax.hdf5')\n",
        "\n",
        "del model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHtdjBU9qAnu",
        "outputId": "afc992d6-04a0-434e-8873-0d03696a496c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch:  40\n",
            "Loading and preparing data for training, and evaluating the model\n",
            "Data dimensions:\n",
            "X: Training data's shape :  (41898, 475)\n",
            "y: Training data's shape :  (41898,)\n",
            "X: Validation data's shape :  (10774, 475)\n",
            "y: Validation data's shape :  (10774,)\n",
            "X: Testing data's shape :  (7183, 475)\n",
            "y: Testing data's shape :  (7183,)\n",
            "41898 train samples\n",
            "10774 validation samples\n",
            "7183 test samples\n",
            "Model compiled\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 44s - loss: 1.5512 - accuracy: 0.5024 - val_loss: 1.1593 - val_accuracy: 0.6139 - 44s/epoch - 74ms/step\n",
            "Epoch 2/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.8477 - accuracy: 0.7308 - val_loss: 0.9125 - val_accuracy: 0.7111 - 32s/epoch - 54ms/step\n",
            "Epoch 3/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.5941 - accuracy: 0.8135 - val_loss: 0.9079 - val_accuracy: 0.7419 - 32s/epoch - 54ms/step\n",
            "Epoch 4/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.4651 - accuracy: 0.8542 - val_loss: 0.5246 - val_accuracy: 0.8432 - 32s/epoch - 54ms/step\n",
            "Epoch 5/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 33s - loss: 0.3849 - accuracy: 0.8799 - val_loss: 0.5669 - val_accuracy: 0.8336 - 33s/epoch - 54ms/step\n",
            "Epoch 6/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.3358 - accuracy: 0.8968 - val_loss: 0.5045 - val_accuracy: 0.8523 - 32s/epoch - 53ms/step\n",
            "Epoch 7/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.3099 - accuracy: 0.9046 - val_loss: 0.4377 - val_accuracy: 0.8748 - 32s/epoch - 53ms/step\n",
            "Epoch 8/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.2709 - accuracy: 0.9171 - val_loss: 0.2742 - val_accuracy: 0.9176 - 32s/epoch - 54ms/step\n",
            "Epoch 9/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.2499 - accuracy: 0.9245 - val_loss: 0.4196 - val_accuracy: 0.8824 - 32s/epoch - 53ms/step\n",
            "Epoch 10/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.2235 - accuracy: 0.9311 - val_loss: 0.2420 - val_accuracy: 0.9327 - 32s/epoch - 53ms/step\n",
            "Epoch 11/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.2095 - accuracy: 0.9357 - val_loss: 0.5286 - val_accuracy: 0.8518 - 32s/epoch - 53ms/step\n",
            "Epoch 12/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.2000 - accuracy: 0.9391 - val_loss: 0.2375 - val_accuracy: 0.9341 - 32s/epoch - 53ms/step\n",
            "Epoch 13/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1864 - accuracy: 0.9415 - val_loss: 0.3789 - val_accuracy: 0.8926 - 32s/epoch - 53ms/step\n",
            "Epoch 14/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1756 - accuracy: 0.9443 - val_loss: 0.3426 - val_accuracy: 0.9010 - 32s/epoch - 54ms/step\n",
            "Epoch 15/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1650 - accuracy: 0.9490 - val_loss: 0.3189 - val_accuracy: 0.9191 - 32s/epoch - 53ms/step\n",
            "Epoch 16/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1590 - accuracy: 0.9501 - val_loss: 0.3568 - val_accuracy: 0.9070 - 32s/epoch - 53ms/step\n",
            "Epoch 17/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1445 - accuracy: 0.9545 - val_loss: 0.1759 - val_accuracy: 0.9547 - 32s/epoch - 53ms/step\n",
            "Epoch 18/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 31s - loss: 0.1421 - accuracy: 0.9548 - val_loss: 0.1727 - val_accuracy: 0.9517 - 31s/epoch - 53ms/step\n",
            "Epoch 19/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1375 - accuracy: 0.9577 - val_loss: 0.1787 - val_accuracy: 0.9499 - 32s/epoch - 54ms/step\n",
            "Epoch 20/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1311 - accuracy: 0.9596 - val_loss: 0.1451 - val_accuracy: 0.9631 - 32s/epoch - 53ms/step\n",
            "Epoch 21/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1275 - accuracy: 0.9592 - val_loss: 0.2949 - val_accuracy: 0.9257 - 32s/epoch - 53ms/step\n",
            "Epoch 22/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1239 - accuracy: 0.9615 - val_loss: 0.2131 - val_accuracy: 0.9454 - 32s/epoch - 53ms/step\n",
            "Epoch 23/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1173 - accuracy: 0.9621 - val_loss: 0.1458 - val_accuracy: 0.9632 - 32s/epoch - 54ms/step\n",
            "Epoch 24/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1154 - accuracy: 0.9637 - val_loss: 0.2965 - val_accuracy: 0.9244 - 32s/epoch - 53ms/step\n",
            "Epoch 25/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1095 - accuracy: 0.9658 - val_loss: 0.1457 - val_accuracy: 0.9621 - 32s/epoch - 53ms/step\n",
            "Epoch 26/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1084 - accuracy: 0.9661 - val_loss: 0.1395 - val_accuracy: 0.9646 - 32s/epoch - 53ms/step\n",
            "Epoch 27/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1028 - accuracy: 0.9672 - val_loss: 0.1374 - val_accuracy: 0.9655 - 32s/epoch - 54ms/step\n",
            "Epoch 28/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.0959 - accuracy: 0.9692 - val_loss: 0.1500 - val_accuracy: 0.9619 - 32s/epoch - 54ms/step\n",
            "Epoch 29/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.1024 - accuracy: 0.9687 - val_loss: 0.1656 - val_accuracy: 0.9563 - 32s/epoch - 53ms/step\n",
            "Epoch 30/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.0916 - accuracy: 0.9710 - val_loss: 0.1537 - val_accuracy: 0.9613 - 32s/epoch - 53ms/step\n",
            "Epoch 31/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.0917 - accuracy: 0.9710 - val_loss: 0.1826 - val_accuracy: 0.9528 - 32s/epoch - 53ms/step\n",
            "Epoch 32/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.0901 - accuracy: 0.9717 - val_loss: 0.1007 - val_accuracy: 0.9748 - 32s/epoch - 53ms/step\n",
            "Epoch 33/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.0851 - accuracy: 0.9734 - val_loss: 0.1568 - val_accuracy: 0.9626 - 32s/epoch - 54ms/step\n",
            "Epoch 34/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.0867 - accuracy: 0.9719 - val_loss: 0.1256 - val_accuracy: 0.9698 - 32s/epoch - 54ms/step\n",
            "Epoch 35/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.0821 - accuracy: 0.9740 - val_loss: 0.1759 - val_accuracy: 0.9556 - 32s/epoch - 54ms/step\n",
            "Epoch 36/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.0808 - accuracy: 0.9742 - val_loss: 0.1948 - val_accuracy: 0.9538 - 32s/epoch - 53ms/step\n",
            "Epoch 37/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.0831 - accuracy: 0.9733 - val_loss: 0.1410 - val_accuracy: 0.9682 - 32s/epoch - 53ms/step\n",
            "Epoch 38/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 32s - loss: 0.0769 - accuracy: 0.9754 - val_loss: 0.1624 - val_accuracy: 0.9614 - 32s/epoch - 54ms/step\n",
            "Epoch 39/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 31s - loss: 0.0760 - accuracy: 0.9762 - val_loss: 0.1306 - val_accuracy: 0.9673 - 31s/epoch - 53ms/step\n",
            "Epoch 40/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599/599 - 31s - loss: 0.0783 - accuracy: 0.9750 - val_loss: 0.1130 - val_accuracy: 0.9735 - 31s/epoch - 53ms/step\n",
            "225/225 - 2s - loss: 0.1093 - accuracy: 0.9708 - 2s/epoch - 9ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing closed accuracy_without_norm: 0.9707642793655396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################## Calculating mean anchor vectors for each class ######################\n",
        "\n",
        "tflite_model_predictions = model_penultimate.predict(X_train)\n",
        "\n",
        "y_train= np.argmax(y_train,axis=1)\n",
        "y_valid= np.argmax(y_valid,axis=1)\n",
        "y_test= np.argmax(y_test,axis=1)\n",
        "\n",
        "txt_O = \"Mean_{Class1:.0f}\"\n",
        "Means={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Means[txt_O.format(Class1=i)]=np.array([0]*NB_CLASSES)\n",
        "\n",
        "count=[0]*NB_CLASSES\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  k=np.argmax(tflite_model_predictions[i])\n",
        "  if (np.argmax(tflite_model_predictions[i])==y_train[i]):\n",
        "    Means[txt_O.format(Class1=y_train[i])]=Means[txt_O.format(Class1=y_train[i])]+tflite_model_predictions[i]\n",
        "    count[y_train[i]]+=1\n",
        "#print(\"Counts: \",count)\n",
        "\n",
        "Mean_Vectors=[]\n",
        "for i in range(NB_CLASSES):\n",
        "  Means[txt_O.format(Class1=i)]=Means[txt_O.format(Class1=i)]/count[i]\n",
        "  Mean_Vectors.append(Means[txt_O.format(Class1=i)])\n",
        "\n",
        "Mean_vectors=np.array(Mean_Vectors)\n",
        "np.save('/content/temp_variables/Mean_vectors.npy', Mean_vectors, allow_pickle=True)\n",
        "\n",
        "\n",
        "#####################################################################################################\n",
        "tflite_model_predictions = model_penultimate.predict(X_valid)\n",
        "\n",
        "Values={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Values[i]=[0]*NB_CLASSES\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]):\n",
        "        Values[y_valid[i]][k]+=np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])-dist\n",
        "\n",
        "Indexes=[]\n",
        "for i in range(NB_CLASSES):\n",
        "  Indexes.append([])\n",
        "\n",
        "for i in range(NB_CLASSES):\n",
        "  Tot=0\n",
        "  for l in range(20):\n",
        "      Min=min(Values[i])\n",
        "      Tot+=Min\n",
        "      Indexes[i].append(Values[i].index(Min))\n",
        "      Values[i][Values[i].index(Min)]=1000000\n",
        "\n",
        "Indexes=np.array(Indexes)\n",
        "\n",
        "np.save('/content/temp_variables/Values.npy',np.array(Values))\n",
        "np.save('/content/temp_variables/Indexes.npy',Indexes)\n",
        "\n",
        "\n",
        "############## Calculating the 90% Thresholds for each method ##################\n",
        "\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(dist)\n",
        "\n",
        "#print(Distances)\n",
        "Threasholds_1=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  Threasholds_1[j]=Dist[int(len(Dist)*0.90)]\n",
        "\n",
        "\n",
        "np.save('/content/temp_variables/Threasholds_1.npy', Threasholds_1)\n",
        "\n",
        "print(\"Thresholds are calulated for method 1\")\n",
        "\n",
        "############################################################################################\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]) and k in Indexes[y_valid[i]]:\n",
        "        Tot+=(np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])-dist)\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(Tot)\n",
        "\n",
        "#print(Distances)\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.12)]\n",
        "\n",
        "Threasholds_2=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_2.npy', Threasholds_2)\n",
        "\n",
        "print(\"Thresholds are calulated for method 2\")\n",
        "\n",
        "############################################################################################\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]) and k in Indexes[y_valid[i]]:\n",
        "        Tot+=np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])\n",
        "\n",
        "    Tot=dist/Tot\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(Tot)\n",
        "\n",
        "#print(Distances)\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.88)]\n",
        "\n",
        "Threasholds_3=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_3.npy', Threasholds_3)\n",
        "\n",
        "print(\"Thresholds are calulated for method 3\")\n",
        "print(Threasholds_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4_Z_BjLqTeL",
        "outputId": "3f5f276f-b5a3-458e-d2bf-1005fcfeeed6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1310/1310 [==============================] - 7s 5ms/step\n",
            "337/337 [==============================] - 2s 5ms/step\n",
            "Thresholds are calulated for method 1\n",
            "Thresholds are calulated for method 2\n",
            "Thresholds are calulated for method 3\n",
            "[0.0311762  0.0297349  0.02463876 0.03191956 0.03189763 0.02689045\n",
            " 0.0299354  0.02550673 0.03021136 0.02693266 0.02532371 0.02555082\n",
            " 0.03049721 0.02297539 0.02595602 0.02857334 0.02469235 0.02278963\n",
            " 0.02550774 0.03256061 0.01937267 0.03075757 0.02548889 0.03057417\n",
            " 0.02815366 0.02830803 0.02529855 0.03441702 0.03117788 0.0274227\n",
            " 0.03073766 0.02556757 0.03169732 0.02044747 0.02641906 0.03256585\n",
            " 0.04118822 0.02469965 0.02471913 0.02805142]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################################################\n",
        "\n",
        "######################## Evaluating results ##########################\n",
        "dataset_dir=\"/content/gdrive/My Drive/SydneyDatasets/IoT/\"\n",
        "X_open = np.load(dataset_dir+'X_open.npy')\n",
        "y__open = np.load(dataset_dir+'y_open.npy')\n",
        "y_open=np.array([NB_CLASSES]*len(y__open))\n",
        "\n",
        "X_open = X_open.astype('float32')\n",
        "y_open = y_open.astype('int8')\n",
        "\n",
        "X_open = X_open[:, :,np.newaxis]\n",
        "\n",
        "tflite_model_predictions = model_penultimate.predict(X_test)\n",
        "tflite_model_predictions_open = model_penultimate.predict(X_open)\n",
        "\n",
        "#############################################################################################################\n",
        "print()\n",
        "print(\"############## Distance Method 1 #################################\")\n",
        "print()\n",
        "prediction_classes = []\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "\n",
        "    d = np.argmax(tflite_model_predictions[i], axis=0)\n",
        "    if np.linalg.norm(tflite_model_predictions[i] - Mean_vectors[d]) > Threasholds_1[d]:\n",
        "        prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "        prediction_classes.append(d)\n",
        "\n",
        "prediction_classes = np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test)\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "\n",
        "prediction_classes_open = []\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "\n",
        "    d = np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    if np.linalg.norm(tflite_model_predictions_open[i] - Mean_vectors[d]) > Threasholds_1[d]:\n",
        "        prediction_classes_open.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "        prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open = np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open)\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "Matrix = []\n",
        "for i in range(NB_CLASSES + 1):\n",
        "    Matrix.append(np.zeros(NB_CLASSES + 1))\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    Matrix[y_test[i]][prediction_classes[i]] += 1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "    Matrix[y_open[i]][prediction_classes_open[i]] += 1\n",
        "\n",
        "#print(Matrix)\n",
        "\n",
        "print()\n",
        "F1_Score = New_F1_Score(Matrix)\n",
        "print(\"Average novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "F1_Score = Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "F1_Score = Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)\n",
        "\n",
        "#############################################################################################################\n",
        "print()\n",
        "print(\"############## Distance Method 2 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "\n",
        "    d=np.argmax(tflite_model_predictions[i], axis=0)\n",
        "    #dist=np.dot(Mean_vectors[d],tflite_model_predictions[i])\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=d and (k in Indexes[d]):\n",
        "        #Tot+=np.dot(Mean_vectors[k],tflite_model_predictions[i])-dist\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions[i])-dist\n",
        "\n",
        "    if Tot<Threasholds_2[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    #dist=np.dot(Mean_vectors[d],tflite_model_predictions_open[i])\n",
        "    dist = np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_open[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(d) and k in Indexes[d]:\n",
        "        #Tot+=np.dot(Mean_vectors[k],tflite_model_predictions_open[i])-dist\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_open[i])-dist\n",
        "\n",
        "    if Tot<Threasholds_2[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy TFLITE model_Closed_set :', acc_Close)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy TFLITE model_Open_set :', acc_Open)\n",
        "\n",
        "Matrix = []\n",
        "for i in range(NB_CLASSES + 1):\n",
        "    Matrix.append(np.zeros(NB_CLASSES + 1))\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    Matrix[y_test[i]][prediction_classes[i]] += 1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "    Matrix[y_open[i]][prediction_classes_open[i]] += 1\n",
        "\n",
        "#print(Matrix)\n",
        "\n",
        "print()\n",
        "F1_Score = New_F1_Score(Matrix)\n",
        "print(\"Average novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "F1_Score = Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "F1_Score = Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)\n",
        "\n",
        "#############################################################################################################\n",
        "print()\n",
        "print(\"############## Distance Method 3 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "\n",
        "    d=np.argmax(tflite_model_predictions[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d][d]-tflite_model_predictions[i][d])\n",
        "    #dist=np.dot(Mean_vectors[d],tflite_model_predictions[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=d and (k in Indexes[d]):\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions[i])\n",
        "        #Tot+=np.dot(Mean_vectors[k],tflite_model_predictions[i])\n",
        "\n",
        "    Tot=dist/Tot\n",
        "    if Tot>Threasholds_3[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_open[i])\n",
        "    #dist=np.dot(Mean_vectors[d],tflite_model_predictions_open[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(d) and k in Indexes[d]:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_open[i])\n",
        "        #Tot+=np.dot(Mean_vectors[k],tflite_model_predictions_open[i])\n",
        "\n",
        "    Tot=dist/Tot\n",
        "    if Tot>Threasholds_3[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy TFLITE model_Closed_set :', acc_Close)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy TFLITE model_Open_set :', acc_Open)\n",
        "\n",
        "Matrix = []\n",
        "for i in range(NB_CLASSES + 1):\n",
        "    Matrix.append(np.zeros(NB_CLASSES + 1))\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    Matrix[y_test[i]][prediction_classes[i]] += 1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "    Matrix[y_open[i]][prediction_classes_open[i]] += 1\n",
        "\n",
        "#print(Matrix)\n",
        "\n",
        "print()\n",
        "F1_Score = New_F1_Score(Matrix)\n",
        "print(\"Average novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "F1_Score = Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "F1_Score = Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcNvdJzUqJ71",
        "outputId": "d0a112de-6693-439b-9c86-11a3e5445f52"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 1s 5ms/step\n",
            "2716/2716 [==============================] - 14s 5ms/step\n",
            "\n",
            "############## Distance Method 1 #################################\n",
            "\n",
            "Test accuracy Normal model_Closed_set : 0.872476681052485\n",
            "Test accuracy Normal model_Open_set : 0.6776810993715904\n",
            "\n",
            "Precision:  0.1433833683131882\n",
            "Recall:  0.8747819973540342\n",
            "Average novel F1_Score:  0.2463827435462807\n",
            "\n",
            "Micro Precision:  0.1824294821412977\n",
            "Micro Recall:  0.872476681052485\n",
            "Average Micro F1_Score:  0.3017623237958337\n",
            "\n",
            "Precision: 0.3358765986547234\n",
            "Recall: 0.872188537723433\n",
            "Average Macro F1_Score:  0.484986625621071\n",
            "\n",
            "############## Distance Method 2 #################################\n",
            "\n",
            "Test accuracy TFLITE model_Closed_set : 0.8553529166086593\n",
            "Test accuracy TFLITE model_Open_set : 0.7750040282669245\n",
            "\n",
            "Precision:  0.18777923899636917\n",
            "Recall:  0.8579656473508138\n",
            "Average novel F1_Score:  0.30812129594381654\n",
            "\n",
            "Micro Precision:  0.2386297432710607\n",
            "Micro Recall:  0.8553529166086593\n",
            "Average Micro F1_Score:  0.37315517423858086\n",
            "\n",
            "Precision: 0.40388868894878616\n",
            "Recall: 0.8547788492418402\n",
            "Average Macro F1_Score:  0.5485729877722291\n",
            "\n",
            "############## Distance Method 3 #################################\n",
            "\n",
            "Test accuracy TFLITE model_Closed_set : 0.9707643046081025\n",
            "Test accuracy TFLITE model_Open_set : 0.781552839352715\n",
            "\n",
            "Precision:  0.20419602875594584\n",
            "Recall:  0.9718900529921266\n",
            "Average novel F1_Score:  0.3374856493939543\n",
            "\n",
            "Micro Precision:  0.2665214233841685\n",
            "Micro Recall:  0.9707643046081025\n",
            "Average Micro F1_Score:  0.41822107261097397\n",
            "\n",
            "Precision: 0.43243997281044455\n",
            "Recall: 0.9705437778348959\n",
            "Average Macro F1_Score:  0.5982990490285008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k4crCfkxrAbN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}