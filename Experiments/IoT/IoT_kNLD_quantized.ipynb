{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXXZ3xBCoZ-c",
        "outputId": "b0f85482-8109-49c2-fb68-f933f85d1c2c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "directory = \"/content/dataset\"\n",
        "if any(os.listdir(directory)):\n",
        "  print('dataset exists')\n",
        "else:\n",
        "  !unzip /content/dataset -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SFdnbZgRVmv",
        "outputId": "c1ba060e-e2af-425f-ce9f-780c9c97037f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/dataset, /content/dataset.zip or /content/dataset.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "PM1cPJ_soczA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from utility import LoadDataIot\n",
        "from IOT_CNN import DFNet_Dropout  #DFNet_Add_Layer\n",
        "import random\n",
        "import tensorflow\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "from sklearn.metrics import accuracy_score\n",
        "np_config.enable_numpy_behavior()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representative_data_gen_Open():\n",
        "  for input_value in tf.data.Dataset.from_tensor_slices(X_open).batch(1).take(1000):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size\n",
        "\n",
        "def convert_bytes(size, unit=None):\n",
        "    if unit == \"KB\":\n",
        "        return str(round(size / 1024, 3))\n",
        "    elif unit == \"MB\":\n",
        "        return str(round(size / (1024 * 1024), 3))\n",
        "    else:\n",
        "        return str(size)\n",
        "\n",
        "\n",
        "def Micro_F1(matrix):\n",
        "    epsilon = 1e-8\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "\n",
        "    for k in range(NB_CLASSES):\n",
        "        TP += matrix[k][k]\n",
        "        FP += (np.sum(Matrix, axis=0)[k] - matrix[k][k])\n",
        "        TN += (np.sum(Matrix, axis=1)[k] - matrix[k][k])\n",
        "\n",
        "    Micro_Prec = TP / (TP + FP)\n",
        "    Micro_Rec = TP / (TP + TN)\n",
        "    print(\"Micro Precision: \", Micro_Prec)\n",
        "    print(\"Micro Recall: \", Micro_Rec)\n",
        "    Micro_F1 = 2 * Micro_Prec * Micro_Rec / (Micro_Rec + Micro_Prec + epsilon)\n",
        "\n",
        "    return Micro_F1\n",
        "\n",
        "\n",
        "def New_F1_Score(Matrix):\n",
        "    Column_sum = np.sum(Matrix, axis=0)\n",
        "    Raw_sum = np.sum(Matrix, axis=1)\n",
        "\n",
        "    Precision_Differences = []\n",
        "    Recall_Differences = []\n",
        "    for i in range(NB_CLASSES):\n",
        "        Precision_Differences.append(np.abs(2 * Matrix[i][i] - Column_sum[i]))\n",
        "        Recall_Differences.append(np.abs(2 * Matrix[i][i] - Raw_sum[i]))\n",
        "\n",
        "    Precision_Differences = np.array(Precision_Differences)\n",
        "    Precision_Differences_Per = Precision_Differences / np.sum(Precision_Differences)\n",
        "    Recall_Differences = np.array(Recall_Differences)\n",
        "    Recall_Differences_Per = Recall_Differences / np.sum(Recall_Differences)\n",
        "\n",
        "    Precisions = np.zeros(NB_CLASSES)\n",
        "    Recalls = np.zeros(NB_CLASSES)\n",
        "\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    for k in range(len(Precisions)):\n",
        "        Precisions[k] = (Matrix[k][k] / np.sum(Matrix, axis=0)[k])\n",
        "    Precision = np.sum(np.array(Precisions) * Precision_Differences_Per)\n",
        "\n",
        "    for k in range(len(Recalls)):\n",
        "        Recalls[k] = (Matrix[k][k] / np.sum(Matrix, axis=1)[k])  # *Recall_Differences_Per[k]\n",
        "    Recall = np.sum(np.array(Recalls) * Recall_Differences_Per)\n",
        "\n",
        "    print('Precision: ', Precision)\n",
        "    print('Recall: ', Recall)\n",
        "\n",
        "    F1_Score = 2 * Precision * Recall / (Precision + Recall + epsilon)\n",
        "    return F1_Score\n",
        "\n",
        "\n",
        "def Macro_F1(Matrix):\n",
        "    Precisions = np.zeros(NB_CLASSES)\n",
        "    Recalls = np.zeros(NB_CLASSES)\n",
        "\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    for k in range(len(Precisions)):\n",
        "        Precisions[k] = Matrix[k][k] / np.sum(Matrix, axis=0)[k]\n",
        "    # print(Precisions)\n",
        "\n",
        "    Precision = np.average(Precisions)\n",
        "    print(\"Precision:\", Precision)\n",
        "\n",
        "    for k in range(len(Recalls)):\n",
        "        Recalls[k] = Matrix[k][k] / np.sum(Matrix, axis=1)[k]\n",
        "\n",
        "    Recall = np.average(Recalls)\n",
        "    print(\"Recall:\", Recall)\n",
        "\n",
        "    F1_Score = 2 * Precision * Recall / (Precision + Recall + epsilon)\n",
        "    return F1_Score"
      ],
      "metadata": {
        "id": "1xfCexiTEtKt"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python dataset/IoT_Class_filter.py"
      ],
      "metadata": {
        "id": "kmD_ZayDwZKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3579c9a4-34ff-41e5-9cec-d94a59b6ddb5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-02-14 23:20:06.400199: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-14 23:20:06.400260: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-14 23:20:06.401496: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-14 23:20:07.695598: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Data dimensions:\n",
            "X: Training data's shape :  (41898, 475)\n",
            "X: Validating data's shape :  (10774, 475)\n",
            "X: Testing data's shape :  (7183, 475)\n",
            "X: open data's shape :  (86886, 475)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NB_EPOCH = 40   # Number of training epoch\n",
        "print (\"Number of Epoch: \", NB_EPOCH)\n",
        "BATCH_SIZE = 70 # Batch size\n",
        "VERBOSE = 2 # Output display mode\n",
        "LENGTH = 475 # Packet sequence length\n",
        "\n",
        "\n",
        "OPTIMIZER = Adamax(learning_rate=0.05, beta_1=0.9, beta_2=0.999, epsilon=1e-08) # Optimizer\n",
        "\n",
        "NB_CLASSES = 40 # number of outputs = number of classes\n",
        "INPUT_SHAPE = (LENGTH,1)\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "print (\"Loading and preparing data for training, and evaluating the model\")\n",
        "X_train, y_train, X_valid, y_valid, X_test, y_test = LoadDataIot()\n",
        "\n",
        "# Convert data as float32 type\n",
        "X_train = X_train.astype('float32')\n",
        "X_valid = X_valid.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "y_train = y_train.astype('int8')\n",
        "y_valid = y_valid.astype('int8')\n",
        "y_test = y_test.astype('int8')\n",
        "\n",
        "# we need a [Length x 1] x n shape as input to the DF CNN (Tensorflow)\n",
        "X_train = X_train[:, :,np.newaxis]\n",
        "X_valid = X_valid[:, :,np.newaxis]\n",
        "X_test = X_test[:, :,np.newaxis]\n",
        "\n",
        "# Convert class vectors to categorical classes matrices\n",
        "y_train = to_categorical(y_train, NB_CLASSES)\n",
        "y_valid = to_categorical(y_valid, NB_CLASSES)\n",
        "y_test = to_categorical(y_test, NB_CLASSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm1lT_mRXJwD",
        "outputId": "8cfd2904-c927-41f6-8699-9797d1762e33"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch:  40\n",
            "Loading and preparing data for training, and evaluating the model\n",
            "Data dimensions:\n",
            "X: Training data's shape :  (41898, 475)\n",
            "y: Training data's shape :  (41898,)\n",
            "X: Validation data's shape :  (10774, 475)\n",
            "y: Validation data's shape :  (10774,)\n",
            "X: Testing data's shape :  (7183, 475)\n",
            "y: Testing data's shape :  (7183,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DFNet_Dropout.build(input_shape=INPUT_SHAPE, nb_classes=NB_CLASSES)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "print (\"Model compiled\")\n",
        "\n",
        "filepath = '/content/trained_models/IoT.hdf5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Start training\n",
        "history = model.fit(X_train, y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "\t\tverbose=VERBOSE, validation_data=(X_valid, y_valid), callbacks=callbacks_list)\n",
        "\n",
        "#Start evaluating model with testing data\n",
        "\n",
        "model_penultimate = Model(model.input, model.layers[-2].output)\n",
        "model_penultimate.save('/content/trained_models/IoT_without_softmax.hdf5')\n",
        "model_penultimate.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "score_test = model_penultimate.evaluate(X_test, y_test, verbose=VERBOSE)\n",
        "print(\"Testing closed accuracy_without_norm:\", score_test[1])\n",
        "\n",
        "del model\n"
      ],
      "metadata": {
        "id": "pHtdjBU9qAnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def representative_data_gen():\n",
        "  for input_value in tensorflow.data.Dataset.from_tensor_slices(X_train_Rep).batch(1).take(100):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "Block=1000\n",
        "X_train_Rep,y_train_Rep=shuffle(X_train, y_train)\n",
        "X_test = np.load(\"/content/gdrive/My Drive/SydneyDatasets/IoT/X_test_5.npy\")\n",
        "y_test = np.load(\"/content/gdrive/My Drive/SydneyDatasets/IoT/y_test_5.npy\")\n",
        "y_train=np.argmax(y_train, axis=1)\n",
        "y_valid=np.argmax(y_valid, axis=1)\n",
        "#y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "model_penultimate=load_model('/content/trained_models/IoT_without_softmax.hdf5')\n",
        "model_penultimate.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "TF_LITE_MODEL_FILE_NAME = \"tf_lite_model_fullint.tflite\"\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_penultimate)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "#converter.target_spec.supported_types = [tf.float16]       # COnvert to 16 bit\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8  # or tf.uint8\n",
        "converter.inference_output_type = tf.int8\n",
        "converter.supported_ops=tf.lite.OpsSet.TFLITE_BUILTINS_INT8\n",
        "\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_name = \"/content/trained_models/\"+TF_LITE_MODEL_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)\n",
        "\n",
        "# print(\"Original Model Size:\",convert_bytes(get_file_size('/content/trained_models/IoT_without_softmax.hdf5'), \"KB\"),\"KB\")\n",
        "# print(\"Quantized model size:\",convert_bytes(get_file_size(tflite_model_name), \"KB\"),\"KB\")\n",
        "# print()\n",
        "\n",
        "#X_test=np.squeeze(X_test, axis=-1)\n",
        "interpreter = tf.lite.Interpreter(model_path = tflite_model_name)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], (Block, LENGTH, 1))       #change the input shape according to the test dataset dimenssions\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (Block, NB_CLASSES))\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_scale,input_zero_point  = input_details[0][\"quantization\"]\n",
        "print(input_scale,input_zero_point)\n",
        "\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  X_test[i] = X_test[i]/input_scale + input_zero_point\n",
        "\n",
        "X_test=X_test[:,:,np.newaxis]\n",
        "X_test = X_test.astype('int8')\n",
        "tflite_model_predictions_test=[]\n",
        "\n",
        "for i in range(5):\n",
        "  interpreter.set_tensor(input_details[0]['index'], X_test[i*Block:(i+1)*Block])\n",
        "  interpreter.invoke()\n",
        "  Mod_Prediction=interpreter.get_tensor(output_details[0]['index'])\n",
        "  if i==0:\n",
        "    tflite_model_predictions_test=Mod_Prediction\n",
        "  else:\n",
        "    tflite_model_predictions_test=np.concatenate((tflite_model_predictions_test,Mod_Prediction),axis=0)\n",
        "  print(i,\"Done\")\n",
        "\n",
        "acc_ = accuracy_score(np.argmax(tflite_model_predictions_test,axis=1), y_test[:len(tflite_model_predictions_test)])\n",
        "print('Test accuracy TFLITE model :', acc_)\n",
        "\n",
        "del X_test"
      ],
      "metadata": {
        "id": "C4_Z_BjLqTeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir= \"/content/gdrive/My Drive/SydneyDatasets/IoT/\"\n",
        "X_train = np.load(dataset_dir+'X_train_5.npy')\n",
        "X_valid = np.load(dataset_dir+'X_valid_5.npy')\n",
        "\n",
        "\n",
        "X_open = np.load(dataset_dir+'X_open.npy')\n",
        "y__open = np.load(dataset_dir+'y_open.npy')\n",
        "y_open=[NB_CLASSES]*len(y__open)\n",
        "X_open,y_open=shuffle(X_open, y_open)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_valid = X_valid.astype('float32')\n",
        "X_open = X_open.astype('float32')\n",
        "\n",
        "for i in range(NB_CLASSES):\n",
        "  variable_name = f\"Mean_{i}\"\n",
        "  locals()[variable_name]=np.array([0] * NB_CLASSES)\n",
        "\n",
        "#X_train=np.squeeze(X_train, axis=-1)\n",
        "for i in range(len(X_train)):\n",
        "  X_train[i] = X_train[i] / input_scale + input_zero_point\n",
        "\n",
        "X_train = X_train[:, :,np.newaxis]\n",
        "X_train = X_train.astype('int8')\n",
        "\n",
        "Block=1000\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path = tflite_model_name)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], (Block, LENGTH, 1))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (Block, NB_CLASSES))\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "Block=1000\n",
        "tflite_model_predictions = []\n",
        "for i in range(5):\n",
        "  interpreter.set_tensor(input_details[0]['index'], X_train[i*Block:(i+1)*Block])\n",
        "  interpreter.invoke()\n",
        "  Mod_Prediction=interpreter.get_tensor(output_details[0]['index'])\n",
        "  if i==0:\n",
        "    tflite_model_predictions=Mod_Prediction\n",
        "  else:\n",
        "    tflite_model_predictions=np.concatenate((tflite_model_predictions,Mod_Prediction),axis=0)\n",
        "  print(i,\"Done\")\n",
        "\n",
        "del X_train\n",
        "y_train=np.argmax(y_train,axis=1)\n",
        "\n",
        "count=[0]*NB_CLASSES\n",
        "txt_O = \"Mean_{Class1:.0f}\"\n",
        "Means={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Means[txt_O.format(Class1=i)]=np.array([0]*NB_CLASSES)\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  k=np.argmax(tflite_model_predictions[i])\n",
        "  if (np.argmax(tflite_model_predictions[i])==y_train[i]):\n",
        "    Means[txt_O.format(Class1=y_train[i])]=Means[txt_O.format(Class1=y_train[i])]+tflite_model_predictions[i]\n",
        "    count[y_train[i]]+=1\n",
        "print(\"Mean vectors Calculated\")\n",
        "\n",
        "Mean_Vectors=[]\n",
        "for i in range(NB_CLASSES):\n",
        "  Means[txt_O.format(Class1=i)]=Means[txt_O.format(Class1=i)]/count[i]\n",
        "  Mean_Vectors.append(Means[txt_O.format(Class1=i)])\n",
        "\n",
        "\n",
        "Mean_vectors = np.array(Mean_Vectors)\n",
        "np.save('/content/temp_variables/Mean_vectors.npy', Mean_vectors, allow_pickle=True)\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path = tflite_model_name)\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "for i in range(len(X_valid)):\n",
        "  X_valid[i] = X_valid[i] / input_scale + input_zero_point\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path = tflite_model_name)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], (Block, LENGTH, 1))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (Block, NB_CLASSES))\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_scale,input_zero_point  = input_details[0][\"quantization\"]\n",
        "\n",
        "X_valid = X_valid[:, :,np.newaxis]\n",
        "X_valid = X_valid.astype('int8')\n",
        "\n",
        "tflite_model_predictions = []\n",
        "for i in range(5):\n",
        "  interpreter.set_tensor(input_details[0]['index'], X_valid[i*Block:(i+1)*Block])\n",
        "  interpreter.invoke()\n",
        "  Mod_Prediction=interpreter.get_tensor(output_details[0]['index'])\n",
        "  if i==0:\n",
        "    tflite_model_predictions=Mod_Prediction\n",
        "  else:\n",
        "    tflite_model_predictions=np.concatenate((tflite_model_predictions,Mod_Prediction),axis=0)\n",
        "  print(i,\"Done\")\n",
        "\n",
        "del X_valid\n",
        "print(\"Complete\")"
      ],
      "metadata": {
        "id": "rcNvdJzUqJ71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d66181-e3ab-4052-bfab-2ee4d665f497"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Done\n",
            "1 Done\n",
            "2 Done\n",
            "3 Done\n",
            "4 Done\n",
            "Counts:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 113, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-58-553c7315b6de>:65: RuntimeWarning: invalid value encountered in divide\n",
            "  Means[txt_O.format(Class1=i)]=Means[txt_O.format(Class1=i)]/count[i]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Done\n",
            "1 Done\n",
            "2 Done\n",
            "3 Done\n",
            "4 Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_valid= np.argmax(y_valid,axis=1)\n",
        "Values={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Values[i]=[0]*NB_CLASSES\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]):\n",
        "        Values[y_valid[i]][k]+=np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])-dist\n",
        "\n",
        "Indexes=[]\n",
        "for i in range(NB_CLASSES):\n",
        "  Indexes.append([])\n",
        "\n",
        "for i in range(NB_CLASSES):\n",
        "  Tot=0\n",
        "  for l in range(20):\n",
        "      Min=min(Values[i])\n",
        "      Tot+=Min\n",
        "      Indexes[i].append(Values[i].index(Min))\n",
        "      Values[i][Values[i].index(Min)]=1000000\n",
        "\n",
        "Indexes=np.array(Indexes)\n",
        "\n",
        "np.save('/content/temp_variables/Values.npy',np.array(Values))\n",
        "np.save('/content/temp_variables/Indexes.npy',Indexes)\n",
        "\n",
        "\n",
        "############## Calculating the 90% Thresholds for each method ##################\n",
        "\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(dist)\n",
        "\n",
        "#print(Distances)\n",
        "Threasholds_1=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  Threasholds_1[j]=Dist[int(len(Dist)*0.90)]\n",
        "\n",
        "\n",
        "np.save('/content/temp_variables/Threasholds_1.npy', Threasholds_1)\n",
        "\n",
        "print(\"Thresholds are calulated for method 1\")\n",
        "\n",
        "############################################################################################\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]) and k in Indexes[y_valid[i]]:\n",
        "        Tot+=(np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])-dist)\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(Tot)\n",
        "\n",
        "#print(Distances)\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.12)]\n",
        "\n",
        "Threasholds_2=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_2.npy', Threasholds_2)\n",
        "\n",
        "print(\"Thresholds are calulated for method 2\")\n",
        "\n",
        "############################################################################################\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]) and k in Indexes[y_valid[i]]:\n",
        "        Tot+=np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])\n",
        "\n",
        "    Tot=dist/Tot\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(Tot)\n",
        "\n",
        "#print(Distances)\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.88)]\n",
        "\n",
        "Threasholds_3=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_3.npy', Threasholds_3)\n",
        "\n",
        "print(\"Thresholds are calulated for method 3\")"
      ],
      "metadata": {
        "id": "k4crCfkxrAbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################################################\n",
        "\n",
        "######################## Evaluating results ##########################\n",
        "\n",
        "X_open = np.load(dataset_dir+'X_open.npy')\n",
        "y__open = np.load(dataset_dir+'y_open.npy')\n",
        "y_open=np.array([NB_CLASSES]*len(y__open))\n",
        "\n",
        "X_open = X_open.astype('float32')\n",
        "y_open = y_open.astype('int8')\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path = tflite_model_name)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], (Block, LENGTH, 1))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (Block, NB_CLASSES))\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_scale,input_zero_point  = input_details[0][\"quantization\"]\n",
        "\n",
        "for i in range(len(X_open)):\n",
        "  X_open[i] = X_open[i] / input_scale + input_zero_point\n",
        "\n",
        "X_open = X_open[:, :,np.newaxis]\n",
        "X_open = X_open.astype('int8')\n",
        "\n",
        "tflite_model_predictions_open = []\n",
        "for i in range(5):\n",
        "  interpreter.set_tensor(input_details[0]['index'], X_open[i*Block:(i+1)*Block])\n",
        "  interpreter.invoke()\n",
        "  Mod_Prediction=interpreter.get_tensor(output_details[0]['index'])\n",
        "  if i==0:\n",
        "    tflite_model_predictions_open=Mod_Prediction\n",
        "  else:\n",
        "    tflite_model_predictions_open=np.concatenate((tflite_model_predictions,Mod_Prediction),axis=0)\n",
        "  print(i,\"Done\")\n"
      ],
      "metadata": {
        "id": "Jt_HrJs-HYon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"############## Distance Method 1 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    if np.linalg.norm(tflite_model_predictions_test[i]-Mean_vectors[d])>Threasholds_1[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "tflite_model_predictions_open = model_penultimate.predict(X_open)\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    if np.linalg.norm(tflite_model_predictions_open[i]-Mean_vectors[d])>Threasholds_1[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "y_test=y_test[:len(prediction_classes)]\n",
        "y_open=y_open[:len(prediction_classes_open)]\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "print(\"Average novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "#print('Test accuracy TFLITE model_Closed_set :', acc_Close)\n",
        "#print('Test accuracy TFLITE model_Open_set :', acc_Open)\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "#print('Test accuracy TFLITE model_Closed_set :', acc_Close)\n",
        "#print('Test accuracy TFLITE model_Open_set :', acc_Open)\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################################################\n",
        "print()\n",
        "print(\"############## Distance Method 2 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_test[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=d:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_test[i])-dist\n",
        "\n",
        "    if Tot<Threasholds_2[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "tflite_model_predictions_open = model.predict(X_open)\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_open[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=d:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_open[i])-dist\n",
        "\n",
        "    if Tot<Threasholds_2[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "\n",
        "print(\"Average Novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################################################\n",
        "print()\n",
        "print(\"############## Distance Method 3 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_test[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=d:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_test[i])\n",
        "\n",
        "    Tot=dist/Tot\n",
        "    if Tot>Threasholds_3[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "tflite_model_predictions_open = model.predict(X_open)\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_open[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=d:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_open[i])\n",
        "\n",
        "    Tot=dist/Tot\n",
        "    if Tot>Threasholds_3[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "\n",
        "print(\"Average Novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)"
      ],
      "metadata": {
        "id": "_CLDbBIeHZhb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}