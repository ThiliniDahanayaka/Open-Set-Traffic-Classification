{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enm9BtN2Uonx",
        "outputId": "feef77ca-cb98-4b7d-c9fc-34aebe645889"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/all_dataset/AWF_data.zip'\n",
        "from google.colab import files\n",
        "files.download(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-ClkmqRD3hB5",
        "outputId": "0c24fdd5-09d4-4ea1-9e38-65d630b3b871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_37d85196-27e4-4617-9112-dd7afeaa876f\", \"AWF_data.zip\", 91906045)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "directory = \"/content/dataset\"\n",
        "if any(os.listdir(directory)):\n",
        "  print('dataset exists')\n",
        "  !unzip /content/dataset/AWF_data.zip -d /content/dataset\n",
        "else:\n",
        "  !unzip /content/dataset/AWF_data.zip -d /content/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SFdnbZgRVmv",
        "outputId": "7afe2015-4ed0-43fd-c60f-ed21a7a8af61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset exists\n",
            "Archive:  /content/dataset/AWF_data.zip\n",
            "  inflating: /content/dataset/dataset/X_test.npy  \n",
            "  inflating: /content/dataset/dataset/X_train.npy  \n",
            "  inflating: /content/dataset/dataset/X_valid.npy  \n",
            "  inflating: /content/dataset/dataset/y_test.npy  \n",
            "  inflating: /content/dataset/dataset/y_train.npy  \n",
            "  inflating: /content/dataset/dataset/y_valid.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 15D1vov_iXPWMpGO6-xnb-M6aDXWPxtHD\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYBY7tdaaTEC",
        "outputId": "f09d877d-0c5a-4f00-c436-0430c4afbcc3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=15D1vov_iXPWMpGO6-xnb-M6aDXWPxtHD\n",
            "From (redirected): https://drive.google.com/uc?id=15D1vov_iXPWMpGO6-xnb-M6aDXWPxtHD&confirm=t&uuid=e249a5ee-50e1-45db-b956-0bfd93921f3b\n",
            "To: /content/X_test_Unmon_NoDef.pkl\n",
            "100% 801M/801M [00:05<00:00, 147MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/X_test_Unmon_NoDef.pkl /content/dataset/openset.pkl"
      ],
      "metadata": {
        "id": "ftMzrePpvG-n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PM1cPJ_soczA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from utility import LoadDataNoDefCW\n",
        "from Model_NoDef import DFNet\n",
        "import random\n",
        "import tensorflow\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "from sklearn.metrics import accuracy_score\n",
        "np_config.enable_numpy_behavior()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representative_data_gen_Open():\n",
        "  for input_value in tf.data.Dataset.from_tensor_slices(X__open).batch(1).take(1000):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size\n",
        "\n",
        "def convert_bytes(size, unit=None):\n",
        "    if unit == \"KB\":\n",
        "        return str(round(size / 1024, 3))\n",
        "    elif unit == \"MB\":\n",
        "        return str(round(size / (1024 * 1024), 3))\n",
        "    else:\n",
        "        return str(size)\n",
        "\n",
        "\n",
        "def Micro_F1(matrix):\n",
        "    epsilon = 1e-8\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "\n",
        "    for k in range(NB_CLASSES):\n",
        "        TP += matrix[k][k]\n",
        "        FP += (np.sum(Matrix, axis=0)[k] - matrix[k][k])\n",
        "        TN += (np.sum(Matrix, axis=1)[k] - matrix[k][k])\n",
        "\n",
        "    Micro_Prec = TP / (TP + FP)\n",
        "    Micro_Rec = TP / (TP + TN)\n",
        "    print(\"Micro Precision: \", Micro_Prec)\n",
        "    print(\"Micro Recall: \", Micro_Rec)\n",
        "    Micro_F1 = 2 * Micro_Prec * Micro_Rec / (Micro_Rec + Micro_Prec + epsilon)\n",
        "\n",
        "    return Micro_F1\n",
        "\n",
        "\n",
        "def New_F1_Score(Matrix):\n",
        "    Column_sum = np.sum(Matrix, axis=0)\n",
        "    Raw_sum = np.sum(Matrix, axis=1)\n",
        "\n",
        "    Precision_Differences = []\n",
        "    Recall_Differences = []\n",
        "    for i in range(NB_CLASSES):\n",
        "        Precision_Differences.append(np.abs(2 * Matrix[i][i] - Column_sum[i]))\n",
        "        Recall_Differences.append(np.abs(2 * Matrix[i][i] - Raw_sum[i]))\n",
        "\n",
        "    Precision_Differences = np.array(Precision_Differences)\n",
        "    Precision_Differences_Per = Precision_Differences / np.sum(Precision_Differences)\n",
        "    Recall_Differences = np.array(Recall_Differences)\n",
        "    Recall_Differences_Per = Recall_Differences / np.sum(Recall_Differences)\n",
        "\n",
        "    # print('Precision_Differences_Per',Precision_Differences_Per)\n",
        "    # print('Recall_Differences_Per',Recall_Differences_Per)\n",
        "\n",
        "    Precisions = np.zeros(NB_CLASSES)\n",
        "    Recalls = np.zeros(NB_CLASSES)\n",
        "\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    for k in range(len(Precisions)):\n",
        "        Precisions[k] = (Matrix[k][k] / np.sum(Matrix, axis=0)[k])\n",
        "    Precision = np.sum(np.array(Precisions) * Precision_Differences_Per)\n",
        "\n",
        "    for k in range(len(Recalls)):\n",
        "        Recalls[k] = (Matrix[k][k] / np.sum(Matrix, axis=1)[k])  # *Recall_Differences_Per[k]\n",
        "    Recall = np.sum(np.array(Recalls) * Recall_Differences_Per)\n",
        "\n",
        "    print('Precision: ', Precision)\n",
        "    print('Recall: ', Recall)\n",
        "\n",
        "    F1_Score = 2 * Precision * Recall / (Precision + Recall + epsilon)\n",
        "    return F1_Score\n",
        "\n",
        "\n",
        "def Macro_F1(Matrix):\n",
        "    Precisions = np.zeros(NB_CLASSES)\n",
        "    Recalls = np.zeros(NB_CLASSES)\n",
        "\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    for k in range(len(Precisions)):\n",
        "        Precisions[k] = Matrix[k][k] / np.sum(Matrix, axis=0)[k]\n",
        "    # print(Precisions)\n",
        "\n",
        "    Precision = np.average(Precisions)\n",
        "    print(\"Precision:\", Precision)\n",
        "\n",
        "    for k in range(len(Recalls)):\n",
        "        Recalls[k] = Matrix[k][k] / np.sum(Matrix, axis=1)[k]\n",
        "\n",
        "    Recall = np.average(Recalls)\n",
        "    print(\"Recall:\", Recall)\n",
        "\n",
        "    F1_Score = 2 * Precision * Recall / (Precision + Recall + epsilon)\n",
        "    return F1_Score"
      ],
      "metadata": {
        "id": "1xfCexiTEtKt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c47F0U2wuYf",
        "outputId": "31a21a09-cdd8-41e1-a457-611195b4f49f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NB_EPOCH = 10   # Number of training epoch\n",
        "print (\"Number of Epoch: \", NB_EPOCH)\n",
        "BATCH_SIZE = 128 # Batch size\n",
        "VERBOSE = 2 # Output display mode\n",
        "LENGTH = 1500 # Packet sequence length\n",
        "OPTIMIZER = Adamax(learning_rate=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08) # Optimizer\n",
        "\n",
        "NB_CLASSES = 200 # number of outputs = number of classes\n",
        "INPUT_SHAPE = (LENGTH,1)\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "print (\"Loading and preparing data for training, and evaluating the model\")\n",
        "X_train, y_train, X_valid, y_valid, X_test, y_test = LoadDataNoDefCW()\n",
        "\n",
        "# Convert data as float32 type\n",
        "X_train = X_train.astype('float32')\n",
        "X_valid = X_valid.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "y_valid = y_valid.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "\n",
        "# we need a [Length x 1] x n shape as input to the DF CNN (Tensorflow)\n",
        "X_train = X_train[:, :,np.newaxis]\n",
        "X_valid = X_valid[:, :,np.newaxis]\n",
        "X_test = X_test[:, :,np.newaxis]\n",
        "\n",
        "# Convert class vectors to categorical classes matrices\n",
        "y_train = to_categorical(y_train, NB_CLASSES)\n",
        "y_valid = to_categorical(y_valid, NB_CLASSES)\n",
        "y_test = to_categorical(y_test, NB_CLASSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm1lT_mRXJwD",
        "outputId": "e5e97b14-36cb-45bb-8396-cf9a31d76760"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch:  10\n",
            "Loading and preparing data for training, and evaluating the model\n",
            "Loading non-defended dataset for closed-world scenario\n",
            "Data dimensions:\n",
            "X: Training data's shape :  (100000, 1500)\n",
            "y: Training data's shape :  (100000,)\n",
            "X: Validation data's shape :  (40000, 1500)\n",
            "y: Validation data's shape :  (40000,)\n",
            "X: Testing data's shape :  (40000, 1500)\n",
            "y: Testing data's shape :  (40000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DFNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "print (\"Model compiled\")\n",
        "\n",
        "filepath = '/content/trained_models/AWF.hdf5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Start training\n",
        "history = model.fit(X_train, y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "\t\tverbose=VERBOSE, validation_data=(X_valid, y_valid), callbacks=callbacks_list)\n",
        "\n",
        "#Start evaluating model with testing data\n",
        "\n",
        "model_penultimate = Model(model.input, model.layers[-2].output)\n",
        "model_penultimate.save('/content/trained_models/DF_without_softmax.hdf5')\n",
        "model_penultimate.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "score_test = model_penultimate.evaluate(X_test, y_test, verbose=VERBOSE)\n",
        "print(\"Testing closed accuracy_without_norm:\", score_test[1])\n",
        "\n",
        "del model\n"
      ],
      "metadata": {
        "id": "pHtdjBU9qAnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79942178-78c4-4c67-da64-a79ffd92d6cf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model compiled\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.70505, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 56s - loss: 2.9241 - accuracy: 0.3227 - val_loss: 1.2462 - val_accuracy: 0.7050 - 56s/epoch - 72ms/step\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_accuracy improved from 0.70505 to 0.84525, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 40s - loss: 1.3315 - accuracy: 0.6554 - val_loss: 0.6057 - val_accuracy: 0.8453 - 40s/epoch - 51ms/step\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.84525 to 0.89935, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 40s - loss: 0.8506 - accuracy: 0.7765 - val_loss: 0.3938 - val_accuracy: 0.8993 - 40s/epoch - 52ms/step\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.89935 to 0.91310, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 40s - loss: 0.6250 - accuracy: 0.8367 - val_loss: 0.3380 - val_accuracy: 0.9131 - 40s/epoch - 51ms/step\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.91310 to 0.94275, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 40s - loss: 0.4834 - accuracy: 0.8750 - val_loss: 0.2367 - val_accuracy: 0.9427 - 40s/epoch - 51ms/step\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.94275 to 0.95325, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 40s - loss: 0.3890 - accuracy: 0.8995 - val_loss: 0.1910 - val_accuracy: 0.9532 - 40s/epoch - 51ms/step\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.95325 to 0.95460, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 39s - loss: 0.3249 - accuracy: 0.9167 - val_loss: 0.1848 - val_accuracy: 0.9546 - 39s/epoch - 50ms/step\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.95460 to 0.95987, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 39s - loss: 0.2785 - accuracy: 0.9276 - val_loss: 0.1624 - val_accuracy: 0.9599 - 39s/epoch - 50ms/step\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.95987 to 0.96395, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 40s - loss: 0.2390 - accuracy: 0.9383 - val_loss: 0.1469 - val_accuracy: 0.9639 - 40s/epoch - 51ms/step\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.96395 to 0.96555, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 39s - loss: 0.2121 - accuracy: 0.9441 - val_loss: 0.1413 - val_accuracy: 0.9656 - 39s/epoch - 50ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1250/1250 - 7s - loss: 16.0302 - accuracy: 0.9694 - 7s/epoch - 5ms/step\n",
            "Testing closed accuracy_without_norm: 0.9693750143051147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import _pickle as cPickle\n",
        "dataset_dir = \"/content/dataset/\"\n",
        "with open( dataset_dir+\"openset.pkl\",\"rb\") as f:\n",
        "        X_open = cPickle.load(f,encoding='latin1')\n",
        "X_open = np.array(X_open)\n",
        "X_open=X_open[:,:1500]\n",
        "print(X_open.shape)\n",
        "X_open = X_open.astype('float32')\n",
        "X_open = X_open[:,:,np.newaxis]\n",
        "y_open = np.array([NB_CLASSES]*len(X_open))\n",
        "y_open = y_open.astype('uint8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUs0iOSobKOz",
        "outputId": "9e5acb49-bf33-4b42-eee6-fd9a0f848f52"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 1500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representative_data_gen():\n",
        "  for input_value in tensorflow.data.Dataset.from_tensor_slices(X_train_Rep).batch(1).take(100):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "\n",
        "y_train=np.argmax(y_train, axis=1)\n",
        "y_valid=np.argmax(y_valid, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "tflite_model_predictions_test=model_penultimate.predict(X_test)\n",
        "\n",
        "acc_ = accuracy_score(np.argmax(tflite_model_predictions_test,axis=1), y_test[:len(tflite_model_predictions_test)])\n",
        "print('Test accuracy TFLITE model :', acc_)\n",
        "\n",
        "del X_test\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "C4_Z_BjLqTeL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279e34c5-0757-437b-c00a-f9254bc7ee15"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1250/1250 [==============================] - 6s 4ms/step\n",
            "Test accuracy TFLITE model : 0.969375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2903"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(NB_CLASSES):\n",
        "  variable_name = f\"Mean_{i}\"\n",
        "  locals()[variable_name]=np.array([0] * NB_CLASSES)\n",
        "\n",
        "tflite_model_predictions=model_penultimate.predict(X_train)\n",
        "\n",
        "del X_train\n",
        "\n",
        "count=[0]*NB_CLASSES\n",
        "txt_O = \"Mean_{Class1:.0f}\"\n",
        "Means={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Means[txt_O.format(Class1=i)]=np.array([0]*NB_CLASSES)\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  k=np.argmax(tflite_model_predictions[i])\n",
        "  if (np.argmax(tflite_model_predictions[i])==y_train[i]):\n",
        "    Means[txt_O.format(Class1=y_train[i])]=Means[txt_O.format(Class1=y_train[i])]+tflite_model_predictions[i]\n",
        "    count[y_train[i]]+=1\n",
        "print(\"Counts: \",count)\n",
        "\n",
        "Mean_Vectors=[]\n",
        "for i in range(NB_CLASSES):\n",
        "  Means[txt_O.format(Class1=i)]=Means[txt_O.format(Class1=i)]/count[i]\n",
        "  Mean_Vectors.append(Means[txt_O.format(Class1=i)])\n",
        "\n",
        "Mean_vectors=np.array(Mean_Vectors)\n",
        "\n",
        "\n",
        "Mean_vectors = np.array(Mean_Vectors)\n",
        "np.save('/content/temp_variables/Mean_vectors.npy', Mean_vectors, allow_pickle=True)\n",
        "\n",
        "tflite_model_predictions=model_penultimate.predict(X_valid)\n",
        "\n",
        "del X_valid\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "rcNvdJzUqJ71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a0dd637-8422-4e14-a73a-dbc5172986c4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3125/3125 [==============================] - 17s 5ms/step\n",
            "Counts:  [487, 459, 497, 493, 495, 483, 494, 497, 495, 492, 474, 495, 494, 498, 497, 495, 493, 490, 493, 491, 500, 492, 496, 492, 493, 479, 488, 497, 489, 498, 493, 492, 494, 476, 485, 489, 489, 487, 492, 349, 495, 497, 494, 493, 497, 496, 485, 497, 469, 473, 498, 490, 488, 490, 488, 495, 499, 490, 496, 482, 489, 490, 496, 498, 494, 489, 492, 497, 494, 492, 492, 498, 474, 494, 489, 493, 499, 481, 490, 490, 493, 493, 471, 493, 474, 498, 483, 496, 474, 493, 496, 494, 482, 496, 498, 486, 491, 483, 496, 491, 500, 500, 489, 493, 493, 497, 499, 489, 495, 495, 497, 489, 495, 498, 493, 496, 495, 486, 480, 495, 494, 496, 465, 490, 495, 494, 496, 479, 494, 492, 496, 486, 494, 499, 495, 493, 497, 494, 499, 497, 489, 490, 495, 497, 490, 495, 499, 483, 452, 494, 497, 500, 497, 497, 484, 495, 494, 498, 483, 498, 497, 483, 492, 493, 494, 491, 496, 491, 485, 499, 494, 497, 488, 498, 497, 494, 485, 496, 495, 497, 498, 497, 497, 494, 499, 479, 498, 456, 438, 496, 496, 494, 496, 494, 499, 489, 497, 489, 497, 498]\n",
            "1250/1250 [==============================] - 7s 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1226"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "\n",
        "Indexes=[]\n",
        "for i in range(NB_CLASSES):\n",
        "  Indexes.append([])\n",
        "\n",
        "Values={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Values[i]=[0]*NB_CLASSES\n",
        "\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]):\n",
        "        Values[y_valid[i]][k]+=np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])-dist\n",
        "\n",
        "for i in range(NB_CLASSES):\n",
        "  Tot=0\n",
        "  for l in range(50):\n",
        "      Min=min(Values[i])\n",
        "      Tot+=Min\n",
        "      Indexes[i].append(Values[i].index(Min))\n",
        "      Values[i][Values[i].index(Min)]=1000000\n",
        "\n",
        "Indexes=np.array(Indexes)\n",
        "\n",
        "np.save('/content/temp_variables/Values.npy',np.array(Values))\n",
        "np.save('/content/temp_variables/Indexes.npy',Indexes)\n",
        "\n",
        "print()\n",
        "##################################################################################################\n",
        "print()\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(dist)\n",
        "\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.9)]\n",
        "\n",
        "\n",
        "\n",
        "Threasholds_1=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_1.npy',Threasholds_1)\n",
        "print(\"Thresholds for method 1 calculated\")\n",
        "##################################################################################################\n",
        "print()\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]) and k in Indexes[y_valid[i]]:\n",
        "        Tot+=(np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])-dist)\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(Tot)\n",
        "\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.1)]\n",
        "\n",
        "\n",
        "\n",
        "Threasholds_2=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_2.npy',Threasholds_2)\n",
        "\n",
        "\n",
        "print(\"Thresholds for method 2 calculated\")\n",
        "\n",
        "##################################################################################################\n",
        "print()\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]) and k in Indexes[y_valid[i]]:\n",
        "        Tot+=np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])\n",
        "    Tot=dist/Tot\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(Tot)\n",
        "\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.9)]\n",
        "\n",
        "Threasholds_3=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_3.npy',Threasholds_3)\n",
        "print(\"Thresholds for method 3 calculated\")"
      ],
      "metadata": {
        "id": "k4crCfkxrAbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc4e8086-6177-4a90-8fa7-2e0f7633ce24"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Thresholds for method 1 calculated\n",
            "\n",
            "Thresholds for method 2 calculated\n",
            "\n",
            "Thresholds for method 3 calculated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################################################\n",
        "\n",
        "######################## Evaluating results ##########################\n",
        "tflite_model_predictions_open=model_penultimate.predict(X_open)\n",
        "\n",
        "del X_open\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Jt_HrJs-HYon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c0ba40b-08f8-4d23-dc59-29a01472b671"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 3s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "612"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"############## Distance Method 1 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    if np.linalg.norm(tflite_model_predictions_test[i]-Mean_vectors[d])>Threasholds_1[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    if np.linalg.norm(tflite_model_predictions_open[i]-Mean_vectors[d])>Threasholds_1[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "y_test=y_test[:len(prediction_classes)]\n",
        "y_open=y_open[:len(prediction_classes_open)]\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "print(\"Average novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################################################\n",
        "print()\n",
        "print(\"############## Distance Method 2 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_test[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=d:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_test[i])-dist\n",
        "\n",
        "    if Tot<Threasholds_2[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    dist = np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_open[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(d) and k in Indexes[d]:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_open[i])-dist\n",
        "\n",
        "    if Tot<Threasholds_2[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "\n",
        "print(\"Average Novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################################################\n",
        "print()\n",
        "print(\"############## Distance Method 3 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_test[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=d:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_test[i])\n",
        "\n",
        "    Tot=dist/Tot\n",
        "    if Tot>Threasholds_3[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_open[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(d) and k in Indexes[d]:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_open[i])\n",
        "    Tot=dist/Tot\n",
        "    if Tot>Threasholds_3[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "\n",
        "print(\"Average Novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)"
      ],
      "metadata": {
        "id": "_CLDbBIeHZhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980ec57e-1848-4d80-ba45-f8f6ccee5a79"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############## Distance Method 1 #################################\n",
            "\n",
            "Test accuracy Normal model_Closed_set : 0.87725\n",
            "Test accuracy Normal model_Open_set : 0.9515\n",
            "Precision:  0.9758458968038557\n",
            "Recall:  0.8840715705765407\n",
            "Average novel F1_Score:  0.9276945080844701\n",
            "\n",
            "Micro\n",
            "Micro Precision:  0.9637726935647779\n",
            "Micro Recall:  0.87725\n",
            "Average Micro F1_Score:  0.9184781847530897\n",
            "\n",
            "Macro\n",
            "Precision: 0.9684587513904142\n",
            "Recall: 0.87725\n",
            "Average Macro F1_Score:  0.9206007550370328\n",
            "\n",
            "############## Distance Method 2 #################################\n",
            "\n",
            "Test accuracy Normal model_Closed_set : 0.9688\n",
            "Test accuracy Normal model_Open_set : 0.9725\n",
            "Precision:  0.96567281089131\n",
            "Recall:  0.9722994880546075\n",
            "Average Novel F1_Score:  0.9689748148863533\n",
            "\n",
            "Micro\n",
            "Micro Precision:  0.9579275226182825\n",
            "Micro Recall:  0.9688\n",
            "Average Micro F1_Score:  0.9633330797442367\n",
            "\n",
            "Macro\n",
            "Precision: 0.960575141405872\n",
            "Recall: 0.9688\n",
            "Average Macro F1_Score:  0.9646700345610936\n",
            "\n",
            "############## Distance Method 3 #################################\n",
            "\n",
            "Test accuracy Normal model_Closed_set : 0.969375\n",
            "Test accuracy Normal model_Open_set : 0.96965\n",
            "Precision:  0.9630576788184178\n",
            "Recall:  0.9728743009320905\n",
            "Average Novel F1_Score:  0.9679410960696987\n",
            "\n",
            "Micro\n",
            "Micro Precision:  0.9549081416539428\n",
            "Micro Recall:  0.969375\n",
            "Average Micro F1_Score:  0.9620871845395229\n",
            "\n",
            "Macro\n",
            "Precision: 0.9577827050753615\n",
            "Recall: 0.969375\n",
            "Average Macro F1_Score:  0.9635439823835296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Wt-p1khKa8o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}