{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wsb38XdupwjP",
        "outputId": "315a0bfc-af3d-4c65-9f84-e294e83eae24"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1wHe0FyU3JQKD9yrLdRcpqW3_ztfFQzY2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEhq43qcrDcV",
        "outputId": "32e837f3-f398-4277-b643-a74633158186"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1wHe0FyU3JQKD9yrLdRcpqW3_ztfFQzY2\n",
            "From (redirected): https://drive.google.com/uc?id=1wHe0FyU3JQKD9yrLdRcpqW3_ztfFQzY2&confirm=t&uuid=c5e9f34d-976f-40ba-82cd-296692260b7b\n",
            "To: /content/AWF_data.zip\n",
            "100% 91.9M/91.9M [00:03<00:00, 27.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "directory = \"/content/dataset\"\n",
        "if any(os.listdir(directory)):\n",
        "  print('dataset exists')\n",
        "  !unzip /content/AWF_data.zip -d /content/dataset\n",
        "else:\n",
        "  !unzip /content/AWF_data.zip -d /content/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SFdnbZgRVmv",
        "outputId": "10751fab-9980-4979-c987-368ccd1cd8cc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/AWF_data.zip\n",
            "  inflating: /content/dataset/dataset/X_test.npy  \n",
            "  inflating: /content/dataset/dataset/X_train.npy  \n",
            "  inflating: /content/dataset/dataset/X_valid.npy  \n",
            "  inflating: /content/dataset/dataset/y_test.npy  \n",
            "  inflating: /content/dataset/dataset/y_train.npy  \n",
            "  inflating: /content/dataset/dataset/y_valid.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!gdown 15D1vov_iXPWMpGO6-xnb-M6aDXWPxtHD\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYBY7tdaaTEC",
        "outputId": "72730377-0082-4a7f-cee1-1ad397d9ac60"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=15D1vov_iXPWMpGO6-xnb-M6aDXWPxtHD\n",
            "From (redirected): https://drive.google.com/uc?id=15D1vov_iXPWMpGO6-xnb-M6aDXWPxtHD&confirm=t&uuid=a7e38d2b-f89e-4087-8fae-2be9225e1c19\n",
            "To: /content/X_test_Unmon_NoDef.pkl\n",
            "100% 801M/801M [00:06<00:00, 117MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/X_test_Unmon_NoDef.pkl /content/dataset/openset.pkl"
      ],
      "metadata": {
        "id": "H299FnQf1-9N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PM1cPJ_soczA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from utility import LoadDataNoDefCW\n",
        "from Model_NoDef import DFNet\n",
        "import random\n",
        "import tensorflow\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "from sklearn.metrics import accuracy_score\n",
        "np_config.enable_numpy_behavior()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representative_data_gen_Open():\n",
        "  for input_value in tf.data.Dataset.from_tensor_slices(X__open).batch(1).take(1000):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size\n",
        "\n",
        "def convert_bytes(size, unit=None):\n",
        "    if unit == \"KB\":\n",
        "        return str(round(size / 1024, 3))\n",
        "    elif unit == \"MB\":\n",
        "        return str(round(size / (1024 * 1024), 3))\n",
        "    else:\n",
        "        return str(size)\n",
        "\n",
        "\n",
        "def Micro_F1(matrix):\n",
        "    epsilon = 1e-8\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "\n",
        "    for k in range(NB_CLASSES):\n",
        "        TP += matrix[k][k]\n",
        "        FP += (np.sum(Matrix, axis=0)[k] - matrix[k][k])\n",
        "        TN += (np.sum(Matrix, axis=1)[k] - matrix[k][k])\n",
        "\n",
        "    Micro_Prec = TP / (TP + FP)\n",
        "    Micro_Rec = TP / (TP + TN)\n",
        "    print(\"Micro Precision: \", Micro_Prec)\n",
        "    print(\"Micro Recall: \", Micro_Rec)\n",
        "    Micro_F1 = 2 * Micro_Prec * Micro_Rec / (Micro_Rec + Micro_Prec + epsilon)\n",
        "\n",
        "    return Micro_F1\n",
        "\n",
        "\n",
        "def New_F1_Score(Matrix):\n",
        "    epsilon = 1e-8\n",
        "    Column_sum = np.sum(Matrix, axis=0)\n",
        "    Raw_sum = np.sum(Matrix, axis=1)\n",
        "\n",
        "    Precision_Differences = []\n",
        "    Recall_Differences = []\n",
        "    for i in range(NB_CLASSES):\n",
        "        Precision_Differences.append(np.abs(2 * Matrix[i][i] - Column_sum[i]))\n",
        "        Recall_Differences.append(np.abs(2 * Matrix[i][i] - Raw_sum[i]))\n",
        "\n",
        "    Precision_Differences = np.array(Precision_Differences)\n",
        "    Precision_Differences_Per = Precision_Differences / (np.sum(Precision_Differences)+epsilon)\n",
        "    Recall_Differences = np.array(Recall_Differences)\n",
        "    Recall_Differences_Per = Recall_Differences / (np.sum(Recall_Differences)+epsilon)\n",
        "\n",
        "    # print('Precision_Differences_Per',Precision_Differences_Per)\n",
        "    # print('Recall_Differences_Per',Recall_Differences_Per)\n",
        "\n",
        "    Precisions = np.zeros(NB_CLASSES)\n",
        "    Recalls = np.zeros(NB_CLASSES)\n",
        "\n",
        "    for k in range(len(Precisions)):\n",
        "        Precisions[k] = (Matrix[k][k] / np.sum(Matrix, axis=0)[k])\n",
        "    Precision = np.sum(np.array(Precisions) * Precision_Differences_Per)\n",
        "\n",
        "    for k in range(len(Recalls)):\n",
        "        Recalls[k] = Matrix[k][k] / (np.sum(Matrix, axis=1)[k]+ epsilon)  # *Recall_Differences_Per[k]\n",
        "    Recall = np.sum(np.array(Recalls) * Recall_Differences_Per)\n",
        "\n",
        "    print('Precision: ', Precision)\n",
        "    print('Recall: ', Recall)\n",
        "\n",
        "    F1_Score = 2 * Precision * Recall / (Precision + Recall + epsilon)\n",
        "    return F1_Score\n",
        "\n",
        "\n",
        "def Macro_F1(Matrix):\n",
        "    Precisions = np.zeros(NB_CLASSES)\n",
        "    Recalls = np.zeros(NB_CLASSES)\n",
        "\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    for k in range(len(Precisions)):\n",
        "        Precisions[k] = Matrix[k][k] / (np.sum(Matrix, axis=0)[k]+epsilon)\n",
        "    # print(Precisions)\n",
        "\n",
        "    Precision = np.average(Precisions)\n",
        "    print(\"Precision:\", Precision)\n",
        "\n",
        "    for k in range(len(Recalls)):\n",
        "        Recalls[k] = Matrix[k][k] / (np.sum(Matrix, axis=1)[k]+epsilon)\n",
        "\n",
        "    Recall = np.average(Recalls)\n",
        "    print(\"Recall:\", Recall)\n",
        "\n",
        "    F1_Score = 2 * Precision * Recall / (Precision + Recall + epsilon)\n",
        "    return F1_Score"
      ],
      "metadata": {
        "id": "1xfCexiTEtKt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c47F0U2wuYf",
        "outputId": "d5173baa-f622-4877-96e7-f412501763c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NB_EPOCH = 10   # Number of training epoch\n",
        "print (\"Number of Epoch: \", NB_EPOCH)\n",
        "BATCH_SIZE = 128 # Batch size\n",
        "VERBOSE = 2 # Output display mode\n",
        "LENGTH = 1500 # Packet sequence length\n",
        "OPTIMIZER = Adamax(learning_rate=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08) # Optimizer\n",
        "\n",
        "NB_CLASSES = 200 # number of outputs = number of classes\n",
        "INPUT_SHAPE = (LENGTH,1)\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "print (\"Loading and preparing data for training, and evaluating the model\")\n",
        "X_train, y_train, X_valid, y_valid, X_test, y_test = LoadDataNoDefCW()\n",
        "\n",
        "# Convert data as float32 type\n",
        "X_train = X_train.astype('float32')\n",
        "X_valid = X_valid.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "y_valid = y_valid.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "\n",
        "# we need a [Length x 1] x n shape as input to the DF CNN (Tensorflow)\n",
        "X_train = X_train[:, :,np.newaxis]\n",
        "X_valid = X_valid[:, :,np.newaxis]\n",
        "X_test = X_test[:, :,np.newaxis]\n",
        "\n",
        "# Convert class vectors to categorical classes matrices\n",
        "y_train = to_categorical(y_train, NB_CLASSES)\n",
        "y_valid = to_categorical(y_valid, NB_CLASSES)\n",
        "y_test = to_categorical(y_test, NB_CLASSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm1lT_mRXJwD",
        "outputId": "f0d012bb-e876-49e8-9459-8adec9a5e71f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch:  10\n",
            "Loading and preparing data for training, and evaluating the model\n",
            "Loading non-defended dataset for closed-world scenario\n",
            "Data dimensions:\n",
            "X: Training data's shape :  (100000, 1500)\n",
            "y: Training data's shape :  (100000,)\n",
            "X: Validation data's shape :  (40000, 1500)\n",
            "y: Validation data's shape :  (40000,)\n",
            "X: Testing data's shape :  (40000, 1500)\n",
            "y: Testing data's shape :  (40000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DFNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "print (\"Model compiled\")\n",
        "\n",
        "filepath = '/content/trained_models/AWF.hdf5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Start training\n",
        "history = model.fit(X_train, y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "\t\tverbose=VERBOSE, validation_data=(X_valid, y_valid), callbacks=callbacks_list)\n",
        "\n",
        "#Start evaluating model with testing data\n",
        "\n",
        "model_penultimate = Model(model.input, model.layers[-2].output)\n",
        "model_penultimate.save('/content/trained_models/AWF_without_softmax.hdf5')\n",
        "model_penultimate.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "score_test = model_penultimate.evaluate(X_test, y_test, verbose=VERBOSE)\n",
        "print(\"Testing closed accuracy_without_norm:\", score_test[1])\n",
        "\n",
        "\n",
        "del model\n"
      ],
      "metadata": {
        "id": "pHtdjBU9qAnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ab5cf9-8ecf-4c81-eacd-b6ae3d05969e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model compiled\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.58455, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 60s - loss: 2.9170 - accuracy: 0.3255 - val_loss: 1.5673 - val_accuracy: 0.5846 - 60s/epoch - 77ms/step\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_accuracy improved from 0.58455 to 0.85155, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 39s - loss: 1.3216 - accuracy: 0.6564 - val_loss: 0.5846 - val_accuracy: 0.8515 - 39s/epoch - 49ms/step\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.85155 to 0.89935, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 40s - loss: 0.8469 - accuracy: 0.7777 - val_loss: 0.3956 - val_accuracy: 0.8993 - 40s/epoch - 51ms/step\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.89935 to 0.91835, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 40s - loss: 0.6173 - accuracy: 0.8390 - val_loss: 0.3174 - val_accuracy: 0.9183 - 40s/epoch - 51ms/step\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.91835 to 0.93698, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 40s - loss: 0.4862 - accuracy: 0.8731 - val_loss: 0.2546 - val_accuracy: 0.9370 - 40s/epoch - 51ms/step\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.93698 to 0.95003, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 40s - loss: 0.3933 - accuracy: 0.8992 - val_loss: 0.2022 - val_accuracy: 0.9500 - 40s/epoch - 51ms/step\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.95003 to 0.95592, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 40s - loss: 0.3293 - accuracy: 0.9156 - val_loss: 0.1787 - val_accuracy: 0.9559 - 40s/epoch - 51ms/step\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.95592 to 0.96038, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 40s - loss: 0.2799 - accuracy: 0.9273 - val_loss: 0.1594 - val_accuracy: 0.9604 - 40s/epoch - 51ms/step\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.96038 to 0.96387, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 38s - loss: 0.2403 - accuracy: 0.9375 - val_loss: 0.1502 - val_accuracy: 0.9639 - 38s/epoch - 49ms/step\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.96387 to 0.96715, saving model to /content/trained_models/AWF.hdf5\n",
            "782/782 - 39s - loss: 0.2148 - accuracy: 0.9443 - val_loss: 0.1387 - val_accuracy: 0.9671 - 39s/epoch - 49ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1250/1250 - 7s - loss: 16.0270 - accuracy: 0.9701 - 7s/epoch - 6ms/step\n",
            "Testing closed accuracy_without_norm: 0.9701499938964844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import _pickle as cPickle\n",
        "dataset_dir = \"/content/dataset/\"\n",
        "with open( dataset_dir+\"openset.pkl\",\"rb\") as f:\n",
        "        X_open = cPickle.load(f,encoding='latin1')\n",
        "X_open = np.array(X_open)\n",
        "X_open=X_open[:,:1500]\n",
        "print(X_open.shape)\n",
        "X_open = X_open.astype('float32')\n",
        "X__open = X_open[:,:,np.newaxis]\n",
        "y_open = np.array([NB_CLASSES]*len(X_open))\n",
        "y_open = y_open.astype('uint8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUs0iOSobKOz",
        "outputId": "214858c8-babb-4a2b-879c-02ca8cb9473c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 1500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representative_data_gen():\n",
        "  for input_value in tensorflow.data.Dataset.from_tensor_slices(X_train_Rep).batch(1).take(1000):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "Block=1000\n",
        "X_train_Rep,y_train_Rep=shuffle(X_train, y_train)\n",
        "y_train=np.argmax(y_train, axis=1)\n",
        "y_valid=np.argmax(y_valid, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "X_test=np.squeeze(X_test, axis=-1)\n",
        "\n",
        "TF_LITE_MODEL_FILE_NAME = \"tf_lite_model_fullint.tflite\"\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_penultimate)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "#converter.target_spec.supported_types = [tf.float16]       # COnvert to 16 bit\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8  # or tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_name = \"/content/trained_models/\"+TF_LITE_MODEL_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)\n",
        "\n",
        "# print(\"Original Model Size:\",convert_bytes(get_file_size('/content/trained_models/IoT_without_softmax.hdf5'), \"KB\"),\"KB\")\n",
        "# print(\"Quantized model size:\",convert_bytes(get_file_size(tflite_model_name), \"KB\"),\"KB\")\n",
        "# print()\n",
        "\n",
        "#X_test=np.squeeze(X_test, axis=-1)\n",
        "interpreter = tf.lite.Interpreter(model_path = tflite_model_name)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], (Block, LENGTH, 1))       #change the input shape according to the test dataset dimenssions\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (Block, NB_CLASSES))\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_scale,input_zero_point  = input_details[0][\"quantization\"]\n",
        "\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  X_test[i] = X_test[i] / input_scale + input_zero_point\n",
        "\n",
        "X_test=X_test[:,:,np.newaxis]\n",
        "X_test = X_test.astype('int8')\n",
        "tflite_model_predictions_test=[]\n",
        "\n",
        "for i in range(5):\n",
        "  interpreter.set_tensor(input_details[0]['index'], X_test[i*Block:(i+1)*Block])\n",
        "  interpreter.invoke()\n",
        "  Mod_Prediction=interpreter.get_tensor(output_details[0]['index'])\n",
        "  if i==0:\n",
        "    tflite_model_predictions_test=Mod_Prediction\n",
        "  else:\n",
        "    tflite_model_predictions_test=np.concatenate((tflite_model_predictions_test,Mod_Prediction),axis=0)\n",
        "  print(i,\"Done\")\n",
        "\n",
        "acc_ = accuracy_score(np.argmax(tflite_model_predictions_test,axis=1), y_test[:len(tflite_model_predictions_test)])\n",
        "print('Test accuracy TFLITE model :', acc_)\n",
        "\n",
        "del X_test\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "C4_Z_BjLqTeL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d9bea93-9dae-4db7-f487-38190d491858"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Done\n",
            "1 Done\n",
            "2 Done\n",
            "3 Done\n",
            "4 Done\n",
            "Test accuracy TFLITE model : 0.9776\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3770"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(NB_CLASSES):\n",
        "  variable_name = f\"Mean_{i}\"\n",
        "  locals()[variable_name]=np.array([0] * NB_CLASSES)\n",
        "\n",
        "print(X_train.shape)\n",
        "X_train=np.squeeze(X_train, axis=-1)\n",
        "X_valid=np.squeeze(X_valid, axis=-1)\n",
        "print(X_train.shape)\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "  X_train[i] = X_train[i] / input_scale + input_zero_point\n",
        "\n",
        "X_train = X_train[:, :,np.newaxis]\n",
        "X_train = X_train.astype('int8')\n",
        "\n",
        "# interpreter = tf.lite.Interpreter(model_path = tflite_model_name)\n",
        "# input_details = interpreter.get_input_details()\n",
        "# output_details = interpreter.get_output_details()\n",
        "# interpreter.resize_tensor_input(input_details[0]['index'], (Block, LENGTH, 1))\n",
        "# interpreter.resize_tensor_input(output_details[0]['index'], (Block, NB_CLASSES))\n",
        "# interpreter.allocate_tensors()\n",
        "\n",
        "\n",
        "tflite_model_predictions = []\n",
        "for i in range(20):\n",
        "  interpreter.set_tensor(input_details[0]['index'], X_train[i*Block:(i+1)*Block])\n",
        "  interpreter.invoke()\n",
        "  Mod_Prediction=interpreter.get_tensor(output_details[0]['index'])\n",
        "  if i==0:\n",
        "    tflite_model_predictions=Mod_Prediction\n",
        "  else:\n",
        "    tflite_model_predictions=np.concatenate((tflite_model_predictions,Mod_Prediction),axis=0)\n",
        "  print(i,\"Done\")\n",
        "\n",
        "del X_train\n",
        "\n",
        "count=[0]*NB_CLASSES\n",
        "txt_O = \"Mean_{Class1:.0f}\"\n",
        "Means={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Means[txt_O.format(Class1=i)]=np.array([0]*NB_CLASSES)\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  k=np.argmax(tflite_model_predictions[i])\n",
        "  if (np.argmax(tflite_model_predictions[i])==y_train[i]):\n",
        "    Means[txt_O.format(Class1=y_train[i])]=Means[txt_O.format(Class1=y_train[i])]+tflite_model_predictions[i]\n",
        "    count[y_train[i]]+=1\n",
        "print(\"Counts: \",count)\n",
        "\n",
        "Mean_Vectors=[]\n",
        "for i in range(NB_CLASSES):\n",
        "  Means[txt_O.format(Class1=i)]=Means[txt_O.format(Class1=i)]/count[i]\n",
        "  Mean_Vectors.append(Means[txt_O.format(Class1=i)])\n",
        "\n",
        "Mean_vectors=np.array(Mean_Vectors)\n",
        "\n",
        "\n",
        "Mean_vectors = np.array(Mean_Vectors)\n",
        "np.save('/content/temp_variables/Mean_vectors.npy', Mean_vectors, allow_pickle=True)\n",
        "\n",
        "# interpreter = tf.lite.Interpreter(model_path = tflite_model_name)\n",
        "\n",
        "# input_details = interpreter.get_input_details()\n",
        "# output_details = interpreter.get_output_details()\n",
        "\n",
        "for i in range(len(X_valid)):\n",
        "  X_valid[i] = X_valid[i] / input_scale + input_zero_point\n",
        "\n",
        "# interpreter = tf.lite.Interpreter(model_path = tflite_model_name)\n",
        "# input_details = interpreter.get_input_details()\n",
        "# output_details = interpreter.get_output_details()\n",
        "# interpreter.resize_tensor_input(input_details[0]['index'], (Block, LENGTH, 1))\n",
        "# interpreter.resize_tensor_input(output_details[0]['index'], (Block, NB_CLASSES))\n",
        "# interpreter.allocate_tensors()\n",
        "\n",
        "X_valid = X_valid[:, :,np.newaxis]\n",
        "X_valid = X_valid.astype('int8')\n",
        "\n",
        "tflite_model_predictions = []\n",
        "for i in range(8):\n",
        "  interpreter.set_tensor(input_details[0]['index'], X_valid[i*Block:(i+1)*Block])\n",
        "  interpreter.invoke()\n",
        "  Mod_Prediction=interpreter.get_tensor(output_details[0]['index'])\n",
        "  if i==0:\n",
        "    tflite_model_predictions=Mod_Prediction\n",
        "  else:\n",
        "    tflite_model_predictions=np.concatenate((tflite_model_predictions,Mod_Prediction),axis=0)\n",
        "  print(i,\"Done\")\n",
        "\n",
        "del X_valid\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "rcNvdJzUqJ71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ded39bf7-31c1-4bc6-dbbd-7b655be2e897"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 1500, 1)\n",
            "(100000, 1500)\n",
            "0 Done\n",
            "1 Done\n",
            "2 Done\n",
            "3 Done\n",
            "4 Done\n",
            "5 Done\n",
            "6 Done\n",
            "7 Done\n",
            "8 Done\n",
            "9 Done\n",
            "10 Done\n",
            "11 Done\n",
            "12 Done\n",
            "13 Done\n",
            "14 Done\n",
            "15 Done\n",
            "16 Done\n",
            "17 Done\n",
            "18 Done\n",
            "19 Done\n",
            "Counts:  [83, 84, 108, 91, 113, 80, 106, 100, 96, 112, 104, 98, 89, 105, 94, 104, 102, 111, 102, 109, 90, 103, 102, 93, 78, 105, 93, 93, 104, 117, 92, 119, 96, 80, 105, 94, 85, 109, 100, 95, 110, 102, 85, 92, 103, 95, 101, 98, 76, 98, 108, 85, 112, 89, 90, 107, 90, 96, 96, 103, 102, 104, 104, 106, 106, 90, 109, 102, 105, 108, 116, 83, 93, 102, 102, 94, 102, 81, 89, 99, 110, 104, 105, 101, 91, 110, 92, 101, 91, 110, 100, 104, 104, 110, 97, 107, 82, 89, 104, 99, 101, 109, 112, 103, 89, 85, 94, 106, 103, 94, 101, 103, 91, 103, 108, 104, 103, 102, 80, 81, 81, 91, 83, 97, 96, 90, 96, 88, 86, 85, 92, 109, 89, 114, 95, 98, 99, 90, 109, 124, 87, 104, 102, 112, 102, 92, 114, 89, 93, 107, 99, 104, 90, 89, 89, 89, 100, 96, 85, 113, 113, 78, 108, 90, 89, 106, 92, 96, 91, 101, 104, 88, 107, 100, 134, 107, 89, 110, 92, 88, 102, 96, 99, 90, 99, 107, 97, 87, 80, 113, 103, 95, 110, 95, 91, 94, 90, 82, 101, 95]\n",
            "0 Done\n",
            "1 Done\n",
            "2 Done\n",
            "3 Done\n",
            "4 Done\n",
            "5 Done\n",
            "6 Done\n",
            "7 Done\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "\n",
        "Indexes=[]\n",
        "for i in range(NB_CLASSES):\n",
        "  Indexes.append([])\n",
        "\n",
        "Values={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Values[i]=[0]*NB_CLASSES\n",
        "\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]):\n",
        "        Values[y_valid[i]][k]+=np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])-dist\n",
        "\n",
        "for i in range(NB_CLASSES):\n",
        "  Tot=0\n",
        "  for l in range(30):\n",
        "      Min=min(Values[i])\n",
        "      Tot+=Min\n",
        "      Indexes[i].append(Values[i].index(Min))\n",
        "      Values[i][Values[i].index(Min)]=np.inf\n",
        "\n",
        "Indexes=np.array(Indexes)\n",
        "\n",
        "np.save('/content/temp_variables/Values.npy',np.array(Values))\n",
        "np.save('/content/temp_variables/Indexes.npy',Indexes)\n",
        "\n",
        "print()\n",
        "##################################################################################################\n",
        "print()\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(dist)\n",
        "\n",
        "\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.8)]\n",
        "\n",
        "\n",
        "\n",
        "Threasholds_1=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_1.npy',Threasholds_1)\n",
        "print(\"Thresholds for method 1 calculated\")\n",
        "##################################################################################################\n",
        "print()\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]) and k in Indexes[y_valid[i]]:\n",
        "        Tot+=(np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])-dist)\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(Tot)\n",
        "\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.8)]\n",
        "\n",
        "\n",
        "\n",
        "Threasholds_2=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_2.npy',Threasholds_2)\n",
        "\n",
        "\n",
        "print(\"Thresholds for method 2 calculated\")\n",
        "\n",
        "##################################################################################################\n",
        "print()\n",
        "txt_1 = \"Dist_{Class1:.0f}\"\n",
        "Distances={}\n",
        "for i in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=i)]=[]\n",
        "\n",
        "for i in range(len(tflite_model_predictions)):\n",
        "  if (y_valid[i]==np.argmax(tflite_model_predictions[i])):\n",
        "    dist = np.linalg.norm(Mean_Vectors[y_valid[i]]-tflite_model_predictions[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(y_valid[i]) and k in Indexes[y_valid[i]]:\n",
        "        Tot+=np.linalg.norm(Mean_Vectors[k]-tflite_model_predictions[i])\n",
        "    Tot=dist/Tot\n",
        "    Distances[txt_1.format(Class1=y_valid[i])].append(Tot)\n",
        "\n",
        "TH=[0]*NB_CLASSES\n",
        "for j in range(NB_CLASSES):\n",
        "  Distances[txt_1.format(Class1=j)].sort()\n",
        "  Dist=Distances[txt_1.format(Class1=j)]\n",
        "  TH[j]=Dist[int(len(Dist)*0.2)]\n",
        "\n",
        "Threasholds_3=np.array(TH)\n",
        "np.save('/content/temp_variables/Threasholds_3.npy',Threasholds_3)\n",
        "print(\"Thresholds for method 3 calculated\")"
      ],
      "metadata": {
        "id": "k4crCfkxrAbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ada04c-97f3-4cae-dcbf-16ba20fa5216"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Thresholds for method 1 calculated\n",
            "\n",
            "Thresholds for method 2 calculated\n",
            "\n",
            "Thresholds for method 3 calculated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(len(X_open)):\n",
        "  X_open[i] = X_open[i] / input_scale + input_zero_point\n",
        "\n",
        "X_open = X_open[:, :,np.newaxis]\n",
        "X_open = X_open.astype('int8')\n",
        "\n",
        "for i in range(10):\n",
        "  interpreter.set_tensor(input_details[0]['index'], X_open[i*Block:(i+1)*Block])\n",
        "  interpreter.invoke()\n",
        "  Mod_Prediction=interpreter.get_tensor(output_details[0]['index'])\n",
        "  if i==0:\n",
        "    tflite_model_predictions_open=Mod_Prediction\n",
        "  else:\n",
        "    tflite_model_predictions_open=np.concatenate((tflite_model_predictions,Mod_Prediction),axis=0)\n",
        "  print(i,\"Done\")\n",
        "\n",
        "del X_open\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Jt_HrJs-HYon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb0bd8c-14a0-42d1-ba70-c1a241bba297"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Done\n",
            "1 Done\n",
            "2 Done\n",
            "3 Done\n",
            "4 Done\n",
            "5 Done\n",
            "6 Done\n",
            "7 Done\n",
            "8 Done\n",
            "9 Done\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"############## Distance Method 1 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    if np.linalg.norm(tflite_model_predictions_test[i]-Mean_vectors[d])>Threasholds_1[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    if np.linalg.norm(tflite_model_predictions_open[i]-Mean_vectors[d])>=Threasholds_1[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "y_test=y_test[:len(prediction_classes)]\n",
        "y_open=y_open[:len(prediction_classes_open)]\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "print(\"Average novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################################################\n",
        "print()\n",
        "print(\"############## Distance Method 2 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_test[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=d:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_test[i])-dist\n",
        "\n",
        "    if Tot<Threasholds_2[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    dist = np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_open[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(d) and k in Indexes[d]:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_open[i])-dist\n",
        "\n",
        "    if Tot<=Threasholds_2[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "\n",
        "print(\"Average Novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################################################\n",
        "print()\n",
        "print(\"############## Distance Method 3 #################################\")\n",
        "print()\n",
        "prediction_classes=[]\n",
        "for i in range(len(tflite_model_predictions_test)):\n",
        "    d=np.argmax(tflite_model_predictions_test[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_test[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=d:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_test[i])\n",
        "\n",
        "    Tot=dist/Tot\n",
        "    if Tot>Threasholds_3[d]:\n",
        "      prediction_classes.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes.append(d)\n",
        "\n",
        "prediction_classes=np.array(prediction_classes)\n",
        "acc_Close = accuracy_score(prediction_classes, y_test[:len(prediction_classes)])\n",
        "print('Test accuracy Normal model_Closed_set :', acc_Close)\n",
        "\n",
        "\n",
        "prediction_classes_open=[]\n",
        "for i in range(len(tflite_model_predictions_open)):\n",
        "    d=np.argmax(tflite_model_predictions_open[i], axis=0)\n",
        "    dist=np.linalg.norm(Mean_vectors[d]-tflite_model_predictions_open[i])\n",
        "    Tot=0\n",
        "    for k in range(NB_CLASSES):\n",
        "      if k!=int(d) and k in Indexes[d]:\n",
        "        Tot+=np.linalg.norm(Mean_vectors[k]-tflite_model_predictions_open[i])\n",
        "    Tot=dist/Tot\n",
        "    if Tot>=Threasholds_3[d]:\n",
        "      prediction_classes_open.append(NB_CLASSES)\n",
        "\n",
        "    else:\n",
        "      prediction_classes_open.append(d)\n",
        "\n",
        "prediction_classes_open=np.array(prediction_classes_open)\n",
        "\n",
        "acc_Open = accuracy_score(prediction_classes_open, y_open[:len(prediction_classes_open)])\n",
        "print('Test accuracy Normal model_Open_set :', acc_Open)\n",
        "\n",
        "Matrix=[]\n",
        "for i in range(NB_CLASSES+1):\n",
        "  Matrix.append(np.zeros(NB_CLASSES+1))\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  Matrix[y_test[i]][prediction_classes[i]]+=1\n",
        "\n",
        "for i in range(len(y_open)):\n",
        "  Matrix[y_open[i]][prediction_classes_open[i]]+=1\n",
        "\n",
        "F1_Score=New_F1_Score(Matrix)\n",
        "\n",
        "print(\"Average Novel F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Micro\")\n",
        "F1_Score=Micro_F1(Matrix)\n",
        "print(\"Average Micro F1_Score: \", F1_Score)\n",
        "\n",
        "print()\n",
        "print(\"Macro\")\n",
        "F1_Score=Macro_F1(Matrix)\n",
        "print(\"Average Macro F1_Score: \", F1_Score)"
      ],
      "metadata": {
        "id": "_CLDbBIeHZhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81a2474-27e9-4f69-8907-c06e9fd7a400"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############## Distance Method 1 #################################\n",
            "\n",
            "Test accuracy Normal model_Closed_set : 0.7874\n",
            "Test accuracy Normal model_Open_set : 0.31377777777777777\n",
            "Precision:  0.30752538503285365\n",
            "Recall:  0.804659011787169\n",
            "Average novel F1_Score:  0.4449856892482909\n",
            "\n",
            "Micro\n",
            "Micro Precision:  0.38887791386803633\n",
            "Micro Recall:  0.7874\n",
            "Average Micro F1_Score:  0.5206294586789234\n",
            "\n",
            "Macro\n",
            "Precision: 0.10417420432435741\n",
            "Recall: 0.09842499999507874\n",
            "Average Macro F1_Score:  0.10121802391539252\n",
            "\n",
            "############## Distance Method 2 #################################\n",
            "\n",
            "Test accuracy Normal model_Closed_set : 0.9766\n",
            "Test accuracy Normal model_Open_set : 0.84\n",
            "Precision:  0.748295065117274\n",
            "Recall:  0.9770898027187136\n",
            "Average Novel F1_Score:  0.8475227607974043\n",
            "\n",
            "Micro\n",
            "Micro Precision:  0.7611847233047545\n",
            "Micro Recall:  0.9766\n",
            "Average Micro F1_Score:  0.8555409499607548\n",
            "\n",
            "Macro\n",
            "Precision: 0.12022514175732357\n",
            "Recall: 0.12207499999389626\n",
            "Average Macro F1_Score:  0.1211430044365836\n",
            "\n",
            "############## Distance Method 3 #################################\n",
            "\n",
            "Test accuracy Normal model_Closed_set : 0.9766\n",
            "Test accuracy Normal model_Open_set : 0.8354444444444444\n",
            "Precision:  0.7405580841243079\n",
            "Recall:  0.9771401594119546\n",
            "Average Novel F1_Score:  0.8425566514785553\n",
            "\n",
            "Micro\n",
            "Micro Precision:  0.7542477602718567\n",
            "Micro Recall:  0.9766\n",
            "Average Micro F1_Score:  0.8511417067785239\n",
            "\n",
            "Macro\n",
            "Precision: 0.12003626101759572\n",
            "Recall: 0.12207499999389623\n",
            "Average Macro F1_Score:  0.12104704173226857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Wt-p1khKa8o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}